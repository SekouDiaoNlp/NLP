{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "venv_shyam",
      "language": "python",
      "name": "venv_shyam"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Document_Similarity_Word2Vec_TfIdf.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYcIKBYxHjqk",
        "colab_type": "text"
      },
      "source": [
        "Steps:\n",
        "- Preprocessing --> removing space, punctuations, stopwords, lemmatization\n",
        "- Create Dictionary\n",
        "- Create bag of words corpus\n",
        "- Apply tf-idf on bow corpus\n",
        "- Create a tf-idf vector of docs \n",
        "- Create a vector of embeddings using spacy 'en' model\n",
        "- Get a dot product of tf-idf vector and embeddings vector\n",
        "\n",
        "Repeat above steps for a new document and\n",
        "calculate cosine similarity between the two embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ip9JU8WHjqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "nlp  = spacy.load('en_core_web_sm')\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "from gensim.matutils import sparse2full\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwnS8wrsHjqv",
        "colab_type": "code",
        "outputId": "3f0f2b97-e69e-4a78-bf2f-a7d707ea2725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "file = '/home/inno/innovation/Shyam/Entity_Extraction/SOWEntityExtraction/output/sow_entities.csv'\n",
        "df = pd.read_csv(file, names = ['FirstParty','SecondParty', 'EffectiveDate','EndDate','Duration','Contract','Services','PaymentTerms'])\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2014473cc464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/inno/innovation/Shyam/Entity_Extraction/SOWEntityExtraction/output/sow_entities.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'FirstParty'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SecondParty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EffectiveDate'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EndDate'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Duration'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Contract'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Services'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PaymentTerms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/home/inno/innovation/Shyam/Entity_Extraction/SOWEntityExtraction/output/sow_entities.csv' does not exist: b'/home/inno/innovation/Shyam/Entity_Extraction/SOWEntityExtraction/output/sow_entities.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ehNDFfHjq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keep_token(t):\n",
        "    return (t.is_alpha and \n",
        "            not (t.is_space or t.is_punct or \n",
        "                 t.is_stop or t.like_num))\n",
        "\n",
        "def lemmatize_doc(doc):\n",
        "    return [ t.lemma_ for t in doc if keep_token(t)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIegrSwEHjrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(docs):\n",
        "    docs = [lemmatize_doc(nlp(doc)) for doc in docs]\n",
        "    docs_dict = Dictionary(docs)\n",
        "    #test_docs_dict.filter_extremes(no_below=20, no_above=0.2)\n",
        "    docs_dict.compactify()\n",
        "    docs_corpus = [docs_dict.doc2bow(doc) for doc in docs]\n",
        "    model_tfidf = TfidfModel(docs_corpus, id2word=docs_dict)\n",
        "    docs_tfidf  = model_tfidf[docs_corpus]\n",
        "    docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfidf])\n",
        "    tfidf_emb_vecs = np.vstack([nlp(docs_dict[i]).vector for i in range(len(docs_dict))])\n",
        "    docs_emb = np.dot(docs_vecs, tfidf_emb_vecs)\n",
        "    return docs_emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH3PRatfHjrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = []\n",
        "for i in range(len(df.Services)):\n",
        "    if(type(df.Services[i]) != float):\n",
        "        docs.append(df.Services[i])\n",
        "docs_emb = get_embeddings(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBlT7xPfHjrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_cosine_distance(test_docs_emb, docs_emb):\n",
        "    max_cosine = 0    \n",
        "    para_with_max_cosine = None\n",
        "    for i in range(test_docs_emb.shape[0]):\n",
        "        vector_1 = test_docs_emb[i]    \n",
        "        for j in range(docs_emb.shape[0]):\n",
        "            vector_2 = docs_emb[j]        \n",
        "            cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
        "            cosine = round((1-cosine)*100,2)        \n",
        "            if(not(np.isnan(cosine))):\n",
        "                if(cosine > max_cosine):\n",
        "                    max_cosine = cosine\n",
        "                    para = i\n",
        "                            \n",
        "    return max_cosine, para"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Brt331VHjrX",
        "colab_type": "code",
        "outputId": "22a83d20-724c-486e-8f12-3ae7d24717b9",
        "colab": {}
      },
      "source": [
        "path = '/home/inno/innovation/Shyam/Entity_Extraction/data/sow_converted_text/'\n",
        "files = os.listdir(path)\n",
        "for i, file in enumerate(files):\n",
        "    if(i<10):\n",
        "        f = open(path + file, \"r\")\n",
        "        text = f.read()\n",
        "        test_docs = text.split('.\\n\\n')\n",
        "        test_docs_emb = get_embeddings(test_docs)    \n",
        "        max_cosine, para = calculate_cosine_distance(test_docs_emb, docs_emb)\n",
        "        print('Below paragraphs #{} in file {} is with max cosine similarity of {} \\n {} \\n'.format(para, file, max_cosine, test_docs[para].replace(\"\\n\", \" \")))                "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/inno/.local/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Below paragraphs #20 in file D29087.pdf.out.html.txt is with max cosine similarity of 99.2 \n",
            "  Virtustream agrees to keep commercially reasonable records of all expenses to support claims for   reimbursement from Customer. Expenses for time spent by Virtustream in traveling to and from   Customer facilities are not reimbursable. Virtustream shall utilize reasonable efforts to minimize the   cost of expenses incurred as follows: no first class travel, no luxury car rentals, no luxury hotel rentals,   no Juxury restaurants, no utilization of airline with preferable frequent flier program when   significantly less expensive alternative is available. In addition, Virtustream will work with Wolters   Kluwer Financia! Services travel services personnel to obtain discounts or other benefits available \n",
            "\n",
            "Below paragraphs #1 in file D15044.pdf.out.html.txt is with max cosine similarity of 99.13 \n",
            "  1. Services: DGSL shal! provide the following services to Loislaw:   Data capture and XML conversion of antitrust trade case law from source documents provided to   DGSL by Loistaw in pdf format \n",
            "\n",
            "Below paragraphs #23 in file D37108.pdf.out.html.txt is with max cosine similarity of 99.27 \n",
            "  *« DeVelop and test interface from Synygy system to SAP BW   « On-going support of Synygy interface Into SAP BW   e Bui ld/Test/Deploy security requirements as per GROM provided security   architecture design   7.0 - Deliverables:   Change Management plan.that addresses communications and training   User Requirements:Document   Functional and Technical Specifications   All in-scope reports and under lyi -databases: and extractors: developed   A Security:architecture design that: appropriately balances the needs of end-user access   - with-data security   Allin-scopefunctionality designed, built, tested, and deployed to. Production   itis estimated that this-effort-will take 8 weeks to complete depending on resource availability   and. will: begin the week.of June 16\", 2014: and complete mid-August, 2014. The resources   require to: provide: the aforementioned services and thelr i-nesouiatad hourly rates along with   aswtravel | $7,224.00   40% Hou rs Contingency ,   | Subtotal | _ $60,184.00 \n",
            "\n",
            "Below paragraphs #16 in file D37508.pdf.out.html.txt is with max cosine similarity of 99.18 \n",
            "  Key Activities:   * Analyze information to formulate findings and document current state assessment   * Compare findings to best practices and available industry benchmarks   ¢ Identify and develop recommendations   * Validate findings and recommendations   * Presentation of findings and recommendations to the core project team (budget impact of   any additional presentations will be discussed and agreed upon.)   Key Deliverables:   ¢ Draft and Final report including prioritized Key Findings with business impact and   Recommendation Summary focused on delivery of commercial legal services across the   Wolters Kluwer portfolio   4. Develop Implementation Roadmap: Develop prioritized implementation plan   Key Activities:   ¢ Develop and validate prioritized implementation roadmap encompassing a 3 year   implementation period   * Identify key change management requirements   Key Deliverables:   ¢ Draft and Final Implementation Roadmap   We will not be auditing any financial statements or performing attest procedures with respect to   information in conjunction with this engagement. Our services are not designed, nor should they   be relied upon, to disclose weaknesses in internal controls, financial statement errors,   irregularities, illegal acts or disclosure deficiencies \n",
            "\n",
            "Below paragraphs #10 in file D35327.pdf.out.html.txt is with max cosine similarity of 99.01 \n",
            "  Notwithstanding the foregoing, Contour acknowledges this SOW does not   include a guarantee of a minimum amount of consulting work to be performed   sow for ATLAS Development Page 3 of 5   Contour Technology Inc. —   . All engagements will be on T&M (time and material) basis   3. Engagement Specifics   Contour consultants will be assigned and report status to WKSS managers located in   the Wolters Kluwer Babylon office \n",
            "\n",
            "Below paragraphs #9 in file D41305.pdf.out.html.txt is with max cosine similarity of 99.41 \n",
            "  Service Provider will identify and, with the prior approval of CCH, implement ongoing process   improvements as part of the Services. At the end of every quarter, starting 6 months after the   SOW Effective Date, Service Provider will evaluate process, tools and deliverables and provide   CCH with a written continuous improvement plan for each one for CCH’s review, comment and   approval. Each of the continuous improvement plans will focus on such areas as resource   reallocation, cross-training, development and/or streamlining of specific standard operating   2 OF 15   Schedule 1 — Service Provider FTE Role Descriptions   [Role | Description | Job Qualifications   Case   Reporter   Researching and acquiring information for our   editorial staff. The primary receivers of the   information they gather are the editors and   subject matter experts who produce our daily   products, including   - Monitoring relevant blogs for   information our editors are interested in \n",
            "\n",
            "Below paragraphs #17 in file D07673.pdf.out.html.txt is with max cosine similarity of 98.88 \n",
            "  Corporation and will be billed in US Dollars. The rate charged will be $1,750 USD plus expenses   The labor component shown month wise split-up of the cost is as follows in $ (USD)   Not to Exceed (USD) $8,750 USD   The fees are based on the following:   o The will work at the DAVID CONSULTING GROUP location at Avon Lake OH United States   Billing will be done on a monthly basis, based on 8 hours per day and 5 days a week. Any additional effort (over 40 hours   per 5 day work week) will be carried out after written approvals by WK Project Manager \n",
            "\n",
            "Below paragraphs #1 in file D19119.pdf.out.html.txt is with max cosine similarity of 99.0 \n",
            "  WHEREAS, WKUS business units are premier publishers of books, journals, magazines, tabloids   and newsletters in both printed and electronic form, as well as distributors of content;   WHEREAS, WKUS and its Affiliates (collectively, “Wolters Kluwer’) wish to procure from   Service Provider pre-press services to support WKUS’s pre-press development, maintenance, and   production operation on Wolters Kluwer’s behalf globally;   WHEREAS, CCH is an Affiliate of WKUS and wishes to procure such services;   WHEREAS, Service Provider provides such services; and   NOW, THEREFORE, in consideration of the foregoing, the covenants in the Agreement and this   SOW, and other good and valuable consideration, the receipt and sufficiency of which are hereby   acknowledged, the parties hereby agree as follows:   Pursuant to the Agreement, Service Provider agrees to provide the services set forth in this SOW   to CCH on the terms provided in the Agreement and pursuant to the specifications provided in this SOW \n",
            "\n",
            "Below paragraphs #24 in file D01539.pdf.out.html.txt is with max cosine similarity of 99.19 \n",
            "  RSC Account Manager Managing all contractual, legal, and commercial issues   Facilitate the availability of all resources to the project   team throughout the project life cycle   First level escalation   WK Project Manager Overall project coordination and monitoring   Coordinate with RSC Project Team on project related   assignments /issues/deliveries   Formal approval/sign-off   Formal approvals on change requests   WK Project Lead Project planning and monitoring   Handover work to RSC   Requirement clarification/verification with RSC team   Ensures timely availability of receivables to RSC as   required   Deliverables verification   3.1. WOLTERS KLUWER Responsibilities   Wolters Kluwer will facilitate and provide product access and functional specification documents   for engagement tasks. WK will provide clarifications to RSC queries in a timely manner. WK will   approve/sign-off all major deliverables in writing to allow closure of corresponding phase/delivery   or to start next project phase \n",
            "\n",
            "Below paragraphs #1 in file D32554.pdf.out.html.txt is with max cosine similarity of 98.02 \n",
            "  re   re   a   ce   ee   ee   rr   Areas Out of Scope   ee   re   re   i   rr   re   rr   i   a   rr   rr   re   rr   ee   rr   re   rr   a   rs   Page 3   Statement of Work, Microsoft Azure Assistance   Prepared by John Johanneson   “Wolters Kluwer - Azure Assistance SOW for WO USCENT-MW15106738.DOCX\"   | WT   | Microsoft ee   eA Project Approach, Timeline and Service   Deliverables   2.1. Approach   a   rr   ee   rr   2.2 Timeline   a   a   rr   2.3. Work Products   a   rc   re   re re   2.4 Project Governance Approach   rr   ale (oe   Statement of Work, Microsoft Azure Assistance   Prepared by John Johanneson   “Wolters Kluwer - Azure Assistance SOW for WO USCENT-MW15106738.DOCX\"   | WT   | Microsoft ee   2.4.1 Communication Plan   ee   a   rr   ee   rr   re   i   re   rr   2.4.2 Issue/Risk Management Procedure   i   re   2.4.3. Change Management Process   rr   rr   re   rr   ce   a   a   rr   rr   Page 5   Statement of Work, Microsoft Azure Assistance   Prepared by John Johanneson   “Wolters Kluwer - Azure Assistance SOW for WO USCENT-MW15106738.DOCX\"   |r   re   2.44 Escalation Process   a   a   rr   re   re   a   re   re   re   ee   rs   re   a   a   a   re   a   ee   re   re   a   i   a   2.5 Project Completion   a   rr   rr   Page 6   Statement of Work, Microsoft Azure Assistance   Prepared by John Johanneson   “Wolters Kluwer - Azure Assistance SOW for WO USCENT-MW15106738.DOCX\"   |r   re   s Project Organization and Staffing   cm   Project Organization Structure   rr   3.2   Project Roles and Responsibilities   a   Customer Project Roles and Responsibilities   Table 1: Customer roles and responsibilities   re   a   re   ee   a   a   i   re   re   ce   re   re   ee   rs   re   ee   an   rr   ee   i   re   i   ee   rr   ee   ee   a   re   re   ace lord   Statement of Work, Microsoft Azure Assistance   Prepared by John Johanneson   “Wolters Kluwer - Azure Assistance SOW for WO USCENT-MW15106738.DOCX\"   | WT   | Microsoft ee   re   re i   ee rr   re   re   rr   ee   rr   rr   re   ne   es   ee   re   a   re   a   a   ee   re   Table 1. Microsoft Roles and Responsibilities   a-\\e( ous]   Statement of Work, Microsoft Azure Assistance   Prepared by John Johanneson   “Wolters Kluwer - Azure Assistance SOW for WO USCENT-MW15106738.DOCX\" \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd36AwTSHjre",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "http://dsgeek.com/2018/02/19/tfidf_vectors.html\n",
        "\n",
        "https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents\n",
        "\n",
        "https://stackoverflow.com/questions/30285706/detecting-similar-paragraphs-in-two-documents\n"
      ]
    }
  ]
}
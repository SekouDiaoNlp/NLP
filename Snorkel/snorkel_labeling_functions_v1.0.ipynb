{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):        \n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub(r'[^.0-9a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r'[^.\\w\\s]', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADDENDUM = 0\n",
    "MSA = 1\n",
    "NDA = 2\n",
    "OTHERS = 3\n",
    "SOW = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n"
     ]
    }
   ],
   "source": [
    "path = '/home/user/Shyam/Code/Release_6.0/Dev/Snorkel/data/filtered/'\n",
    "docs = []\n",
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        with open (os.path.join(root+'/'+file), encoding='utf8') as f:            \n",
    "\n",
    "            text = f.read()\n",
    "            text = preprocess(text)                            \n",
    "            docs.append(text)\n",
    "            filenames.append(file)\n",
    "            \n",
    "            if 'msa' in root:\n",
    "                labels.append('MSA')\n",
    "            \n",
    "            if 'sow' in root:\n",
    "                labels.append('SOW')\n",
    "            \n",
    "            if 'addendum' in root:\n",
    "                labels.append('Addendum')\n",
    "                \n",
    "            if 'nda' in root:\n",
    "                labels.append('NDA')\n",
    "                \n",
    "            if 'other' in root:\n",
    "                labels.append('Others')\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D27186.pdf.out.html.txt</td>\n",
       "      <td>loch     woltexs kinwer busines   statement o...</td>\n",
       "      <td>Addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D12738.pdf.out.html.txt</td>\n",
       "      <td>amendment two   to the outsource services agr...</td>\n",
       "      <td>Addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D27843.pdf.out.html.txt</td>\n",
       "      <td>addendum  3 re new schedule c  pricing  of ja...</td>\n",
       "      <td>Addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D04193.pdf.out.html.txt</td>\n",
       "      <td>addendum no. 3   to   master services agreeme...</td>\n",
       "      <td>Addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D01834.pdf.out.html.txt</td>\n",
       "      <td>addendum  4   to     toner contract agreement...</td>\n",
       "      <td>Addendum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                               text  \\\n",
       "0  D27186.pdf.out.html.txt   loch     woltexs kinwer busines   statement o...   \n",
       "1  D12738.pdf.out.html.txt   amendment two   to the outsource services agr...   \n",
       "2  D27843.pdf.out.html.txt   addendum  3 re new schedule c  pricing  of ja...   \n",
       "3  D04193.pdf.out.html.txt   addendum no. 3   to   master services agreeme...   \n",
       "4  D01834.pdf.out.html.txt   addendum  4   to     toner contract agreement...   \n",
       "\n",
       "      label  \n",
       "0  Addendum  \n",
       "1  Addendum  \n",
       "2  Addendum  \n",
       "3  Addendum  \n",
       "4  Addendum  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(filenames, docs, labels)), columns=['filename','text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([278, 467, 134, 257, 264])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.label.map({'Addendum': 0, 'MSA': 1, 'SOW': 4, 'NDA': 2, 'Others': 3})\n",
    "y = np.array(y)\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>D23598.pdf.out.html.txt</td>\n",
       "      <td>CCH   a Wollers Khewer business   Statement o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>D34429.pdf.out.html.txt</td>\n",
       "      <td>HAR 23 2010 TUE 01 42 PM Woltere Kluwer FAX N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>D01930.pdf.out.html.txt</td>\n",
       "      <td>y Wo Ite rs Klu wer North America Shared Serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>D35062.pdf.out.html.txt</td>\n",
       "      <td>AMENDMENT   SCHEDULE A   DUTIES  TERM  AND CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539</td>\n",
       "      <td>D39419.pdf.out.html.txt</td>\n",
       "      <td>AMENDMENT   SCHEDULE A   To   Independent Con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename  \\\n",
       "535  D23598.pdf.out.html.txt   \n",
       "536  D34429.pdf.out.html.txt   \n",
       "537  D01930.pdf.out.html.txt   \n",
       "538  D35062.pdf.out.html.txt   \n",
       "539  D39419.pdf.out.html.txt   \n",
       "\n",
       "                                                  text  \n",
       "535   CCH   a Wollers Khewer business   Statement o...  \n",
       "536   HAR 23 2010 TUE 01 42 PM Woltere Kluwer FAX N...  \n",
       "537   y Wo Ite rs Klu wer North America Shared Serv...  \n",
       "538   AMENDMENT   SCHEDULE A   DUTIES  TERM  AND CO...  \n",
       "539   AMENDMENT   SCHEDULE A   To   Independent Con...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_msa = df[df.label == 'MSA'][['filename','text']]\n",
    "df_msa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_msa = df[df.label == 'MSA']['label'].map({'Addendum': 0, 'MSA': 1, 'SOW': 4, 'NDA': 2, 'Others': 3}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'msa_keywords = [\"indemnification\", \"warranties\", \"force majeure\", \"governing law\", \\n                \"confidential information\", \"project management\", \"remedies\", \"injunctive relief\", \\n                \"conflicts of interest\", \"right to injunction\", \"dispute resolution\", \"confidentiality\", \\n                \"limitation of liability\", \"usage right\", \"remuneration\", \"choice of law\", \"inter company\",\\n                \"validity and enforceability\", \"this agreement\"]\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "\n",
      "  0%|          | 0/467 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 467/467 [00:00<00:00, 3504.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabelingFunction keyword_meaning set forth, Preprocessors: [], LabelingFunction keyword_including without limitation, Preprocessors: [], LabelingFunction keyword_prior written consent, Preprocessors: [], LabelingFunction keyword_intellectual industrial property, Preprocessors: [], LabelingFunction keyword_prior written notice, Preprocessors: [], LabelingFunction keyword_mutually agreed upon, Preprocessors: [], LabelingFunction keyword_force majeure event, Preprocessors: [], LabelingFunction keyword_subject matter hereof, Preprocessors: [], LabelingFunction keyword_forth applicable statement, Preprocessors: [], LabelingFunction regex_agreement, Preprocessors: []]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "\"\"\"msa_keywords = [\"indemnification\", \"warranties\", \"force majeure\", \"governing law\", \n",
    "                \"confidential information\", \"project management\", \"remedies\", \"injunctive relief\", \n",
    "                \"conflicts of interest\", \"right to injunction\", \"dispute resolution\", \"confidentiality\", \n",
    "                \"limitation of liability\", \"usage right\", \"remuneration\", \"choice of law\", \"inter company\",\n",
    "                \"validity and enforceability\", \"this agreement\"]\n",
    "\"\"\"\n",
    "\n",
    "msa_keywords = ['meaning set forth', 'including without limitation', 'prior written consent', \n",
    "                'intellectual industrial property', 'prior written notice', 'mutually agreed upon', \n",
    "                'force majeure event', 'subject matter hereof', 'forth applicable statement']\n",
    "\n",
    "ABSTAIN = -1\n",
    "MSA = 1\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=MSA):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label))\n",
    "\n",
    "labl_functions = []\n",
    "for key in msa_keywords:\n",
    "    labl_functions.append(make_keyword_lf([key]))\n",
    "\n",
    "@labeling_function()\n",
    "def regex_agreement(x):\n",
    "    return MSA if re.search(r\"agreement (.+?) between (.+?) and (.+?)\", x.text) else ABSTAIN\n",
    "    \n",
    "labl_functions.append(regex_agreement)\n",
    "print(labl_functions)\n",
    "\n",
    "applier = PandasLFApplier(lfs=labl_functions)\n",
    "L_train = applier.apply(df=df_msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>keyword_intellectual industrial property</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_forth applicable statement</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_meaning set forth</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_including without limitation</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>0.049251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_prior written consent</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.074946</td>\n",
       "      <td>0.068522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_prior written notice</td>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_mutually agreed upon</td>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.051392</td>\n",
       "      <td>0.034261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_force majeure event</td>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_subject matter hereof</td>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>regex_agreement</td>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.094218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          j Polarity  Coverage  Overlaps  \\\n",
       "keyword_intellectual industrial property  3       []  0.000000  0.000000   \n",
       "keyword_forth applicable statement        8       []  0.000000  0.000000   \n",
       "keyword_meaning set forth                 0      [1]  0.025696  0.008565   \n",
       "keyword_including without limitation      1      [1]  0.064240  0.049251   \n",
       "keyword_prior written consent             2      [1]  0.074946  0.068522   \n",
       "keyword_prior written notice              4      [1]  0.036403  0.029979   \n",
       "keyword_mutually agreed upon              5      [1]  0.051392  0.034261   \n",
       "keyword_force majeure event               6      [1]  0.019272  0.017131   \n",
       "keyword_subject matter hereof             7      [1]  0.027837  0.023555   \n",
       "regex_agreement                           9      [1]  0.160600  0.094218   \n",
       "\n",
       "                                          Conflicts  Correct  Incorrect  \\\n",
       "keyword_intellectual industrial property        0.0        0          0   \n",
       "keyword_forth applicable statement              0.0        0          0   \n",
       "keyword_meaning set forth                       0.0       12          0   \n",
       "keyword_including without limitation            0.0       30          0   \n",
       "keyword_prior written consent                   0.0       35          0   \n",
       "keyword_prior written notice                    0.0       17          0   \n",
       "keyword_mutually agreed upon                    0.0       24          0   \n",
       "keyword_force majeure event                     0.0        9          0   \n",
       "keyword_subject matter hereof                   0.0       13          0   \n",
       "regex_agreement                                 0.0       75          0   \n",
       "\n",
       "                                          Emp. Acc.  \n",
       "keyword_intellectual industrial property        0.0  \n",
       "keyword_forth applicable statement              0.0  \n",
       "keyword_meaning set forth                       1.0  \n",
       "keyword_including without limitation            1.0  \n",
       "keyword_prior written consent                   1.0  \n",
       "keyword_prior written notice                    1.0  \n",
       "keyword_mutually agreed upon                    1.0  \n",
       "keyword_force majeure event                     1.0  \n",
       "keyword_subject matter hereof                   1.0  \n",
       "regex_agreement                                 1.0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "#y = df.label.values\n",
    "LFAnalysis(L=L_train, lfs=labl_functions).lf_summary(y_msa).sort_values(by='Emp. Acc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Arrays must all have the same number of elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-2447ce7c3c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_label_buckets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbuckets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_label_buckets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/snorkel/analysis/error_analysis.py\u001b[0m in \u001b[0;36mget_label_buckets\u001b[0;34m(*y)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0my_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_int_label_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Arrays must all have the same number of elements\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mbuckets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Arrays must all have the same number of elements"
     ]
    }
   ],
   "source": [
    "#Check how many documents from other classes classified as MSA\n",
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets = get_label_buckets(y, L_train[:, 1])\n",
    "\n",
    "for key in buckets.keys():\n",
    "    if key[1] == 1 and key[0] != 1:        \n",
    "        print(df.iloc[buckets[key]].label.value_counts())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>D10962.pdf.out.html.txt</td>\n",
       "      <td>3601 West 76th Street  Suite 250   A  .   m E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003</td>\n",
       "      <td>D06041.pdf.out.html.txt</td>\n",
       "      <td>OLPA2 SOW   . ERITUM PARTNERS   37 Exeter Rd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>D38018.pdf.out.html.txt</td>\n",
       "      <td>May 15  2017   Denise Silva  Managing Editor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1005</td>\n",
       "      <td>D41099.pdf.out.html.txt</td>\n",
       "      <td>AMENDMENT   SCHEDULE A   To   Independent Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1006</td>\n",
       "      <td>D17903.pdf.out.html.txt</td>\n",
       "      <td>06 30 2010 WED 14 27 FAX ZJ001L 028   542 Amh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename  \\\n",
       "1002  D10962.pdf.out.html.txt   \n",
       "1003  D06041.pdf.out.html.txt   \n",
       "1004  D38018.pdf.out.html.txt   \n",
       "1005  D41099.pdf.out.html.txt   \n",
       "1006  D17903.pdf.out.html.txt   \n",
       "\n",
       "                                                   text  \n",
       "1002   3601 West 76th Street  Suite 250   A  .   m E...  \n",
       "1003   OLPA2 SOW   . ERITUM PARTNERS   37 Exeter Rd ...  \n",
       "1004   May 15  2017   Denise Silva  Managing Editor ...  \n",
       "1005   AMENDMENT   SCHEDULE A   To   Independent Con...  \n",
       "1006   06 30 2010 WED 14 27 FAX ZJ001L 028   542 Amh...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sow = df[df.label == 'SOW'][['filename','text']]\n",
    "df_sow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sow = df[df.label == 'SOW']['label'].map({'Addendum': 0, 'MSA': 1, 'SOW': 4, 'NDA': 2, 'Others': 3}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "\n",
      "100%|██████████| 264/264 [00:00<00:00, 3349.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabelingFunction keyword_this sow, Preprocessors: [], LabelingFunction keyword_this statement of work, Preprocessors: [], LabelingFunction keyword_sow effective date, Preprocessors: [], LabelingFunction keyword_statement of work effective date, Preprocessors: [], LabelingFunction keyword_purpose of sow, Preprocessors: [], LabelingFunction keyword_description of services, Preprocessors: [], LabelingFunction keyword_sow start date, Preprocessors: [], LabelingFunction keyword_sow end date, Preprocessors: [], LabelingFunction keyword_resource the work, Preprocessors: [], LabelingFunction keyword_sow assumptions, Preprocessors: [], LabelingFunction keyword_signing and returning this sow, Preprocessors: [], LabelingFunction keyword_sow term, Preprocessors: [], LabelingFunction keyword_sow duration, Preprocessors: []]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>keyword_sow effective date</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_statement of work effective date</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_purpose of sow</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_sow start date</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_resource the work</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_sow assumptions</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_signing and returning this sow</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_sow term</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this sow</td>\n",
       "      <td>0</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this statement of work</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.071970</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_description of services</td>\n",
       "      <td>5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_sow end date</td>\n",
       "      <td>7</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_sow duration</td>\n",
       "      <td>12</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           j Polarity  Coverage  Overlaps  \\\n",
       "keyword_sow effective date                 2       []  0.000000  0.000000   \n",
       "keyword_statement of work effective date   3       []  0.000000  0.000000   \n",
       "keyword_purpose of sow                     4       []  0.000000  0.000000   \n",
       "keyword_sow start date                     6       []  0.000000  0.000000   \n",
       "keyword_resource the work                  8       []  0.000000  0.000000   \n",
       "keyword_sow assumptions                    9       []  0.000000  0.000000   \n",
       "keyword_signing and returning this sow    10       []  0.000000  0.000000   \n",
       "keyword_sow term                          11       []  0.000000  0.000000   \n",
       "keyword_this sow                           0      [4]  0.136364  0.068182   \n",
       "keyword_this statement of work             1      [4]  0.071970  0.064394   \n",
       "keyword_description of services            5      [4]  0.007576  0.003788   \n",
       "keyword_sow end date                       7      [4]  0.007576  0.003788   \n",
       "keyword_sow duration                      12      [4]  0.003788  0.003788   \n",
       "\n",
       "                                          Conflicts  Correct  Incorrect  \\\n",
       "keyword_sow effective date                      0.0        0          0   \n",
       "keyword_statement of work effective date        0.0        0          0   \n",
       "keyword_purpose of sow                          0.0        0          0   \n",
       "keyword_sow start date                          0.0        0          0   \n",
       "keyword_resource the work                       0.0        0          0   \n",
       "keyword_sow assumptions                         0.0        0          0   \n",
       "keyword_signing and returning this sow          0.0        0          0   \n",
       "keyword_sow term                                0.0        0          0   \n",
       "keyword_this sow                                0.0       36          0   \n",
       "keyword_this statement of work                  0.0       19          0   \n",
       "keyword_description of services                 0.0        2          0   \n",
       "keyword_sow end date                            0.0        2          0   \n",
       "keyword_sow duration                            0.0        1          0   \n",
       "\n",
       "                                          Emp. Acc.  \n",
       "keyword_sow effective date                      0.0  \n",
       "keyword_statement of work effective date        0.0  \n",
       "keyword_purpose of sow                          0.0  \n",
       "keyword_sow start date                          0.0  \n",
       "keyword_resource the work                       0.0  \n",
       "keyword_sow assumptions                         0.0  \n",
       "keyword_signing and returning this sow          0.0  \n",
       "keyword_sow term                                0.0  \n",
       "keyword_this sow                                1.0  \n",
       "keyword_this statement of work                  1.0  \n",
       "keyword_description of services                 1.0  \n",
       "keyword_sow end date                            1.0  \n",
       "keyword_sow duration                            1.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "sow_keywords = ['this sow', 'this statement of work', 'description of services', 'sow end date', \n",
    "                'sow duration']\n",
    "\n",
    "ABSTAIN = -1\n",
    "SOW = 4\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=SOW):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "labl_functions = []\n",
    "for key in sow_keywords:\n",
    "    labl_functions.append(make_keyword_lf([key]))\n",
    "\n",
    "print(labl_functions)\n",
    "\n",
    "applier = PandasLFApplier(lfs=labl_functions)\n",
    "L_train = applier.apply(df=df_sow)\n",
    "\n",
    "#labels\n",
    "#y = df_sow.label.values\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=labl_functions).lf_summary(y_sow).sort_values(by='Emp. Acc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Addendum***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      " 19%|█▊        | 261/1400 [00:00<00:00, 2606.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabelingFunction keyword_this addendum, Preprocessors: [], LabelingFunction keyword_this amendment, Preprocessors: [], LabelingFunction keyword_addendum is part of, Preprocessors: [], LabelingFunction keyword_amendment is part of, Preprocessors: [], LabelingFunction keyword_term of this addendum, Preprocessors: [], LabelingFunction keyword_term of this amendment, Preprocessors: [], LabelingFunction keyword_this amendment is made and entered, Preprocessors: [], LabelingFunction keyword_this addendum is made and entered, Preprocessors: [], LabelingFunction keyword_this amendment is entered into, Preprocessors: [], LabelingFunction keyword_this addendum is entered into, Preprocessors: [], LabelingFunction keyword_this amendment is between, Preprocessors: [], LabelingFunction keyword_this addendum is between, Preprocessors: [], LabelingFunction keyword_duration of this addendum, Preprocessors: [], LabelingFunction keyword_duration of this amendment, Preprocessors: [], LabelingFunction keyword_purpose of amendment, Preprocessors: [], LabelingFunction keyword_purpose of addendum, Preprocessors: [], LabelingFunction keyword_addendum shall become effective, Preprocessors: [], LabelingFunction keyword_amendment shall become effective, Preprocessors: [], LabelingFunction regex_addendum, Preprocessors: []]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:00<00:00, 1683.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>keyword_amendment is part of</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_term of this amendment</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this addendum is made and entered</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_amendment shall become effective</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this amendment is between</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this addendum is between</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_duration of this amendment</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_term of this addendum</td>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_addendum shall become effective</td>\n",
       "      <td>16</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_addendum is part of</td>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_duration of this addendum</td>\n",
       "      <td>12</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_purpose of addendum</td>\n",
       "      <td>15</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this addendum</td>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.087143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this amendment</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.030714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>regex_addendum</td>\n",
       "      <td>18</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.065714</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this amendment is entered into</td>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this amendment is made and entered</td>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_purpose of amendment</td>\n",
       "      <td>14</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_this addendum is entered into</td>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             j Polarity  Coverage  Overlaps  \\\n",
       "keyword_amendment is part of                 3       []  0.000000  0.000000   \n",
       "keyword_term of this amendment               5       []  0.000000  0.000000   \n",
       "keyword_this addendum is made and entered    7       []  0.000000  0.000000   \n",
       "keyword_amendment shall become effective    17       []  0.000000  0.000000   \n",
       "keyword_this amendment is between           10       []  0.000000  0.000000   \n",
       "keyword_this addendum is between            11       []  0.000000  0.000000   \n",
       "keyword_duration of this amendment          13       []  0.000000  0.000000   \n",
       "keyword_term of this addendum                4      [0]  0.014286  0.014286   \n",
       "keyword_addendum shall become effective     16      [0]  0.020714  0.020714   \n",
       "keyword_addendum is part of                  2      [0]  0.031429  0.031429   \n",
       "keyword_duration of this addendum           12      [0]  0.017857  0.017857   \n",
       "keyword_purpose of addendum                 15      [0]  0.013571  0.013571   \n",
       "keyword_this addendum                        0      [0]  0.107143  0.087143   \n",
       "keyword_this amendment                       1      [0]  0.062143  0.030714   \n",
       "regex_addendum                              18      [0]  0.065714  0.057857   \n",
       "keyword_this amendment is entered into       8      [0]  0.001429  0.001429   \n",
       "keyword_this amendment is made and entered   6      [0]  0.004286  0.004286   \n",
       "keyword_purpose of amendment                14      [0]  0.000714  0.000714   \n",
       "keyword_this addendum is entered into        9      [0]  0.009286  0.009286   \n",
       "\n",
       "                                            Conflicts  Correct  Incorrect  \\\n",
       "keyword_amendment is part of                      0.0        0          0   \n",
       "keyword_term of this amendment                    0.0        0          0   \n",
       "keyword_this addendum is made and entered         0.0        0          0   \n",
       "keyword_amendment shall become effective          0.0        0          0   \n",
       "keyword_this amendment is between                 0.0        0          0   \n",
       "keyword_this addendum is between                  0.0        0          0   \n",
       "keyword_duration of this amendment                0.0        0          0   \n",
       "keyword_term of this addendum                     0.0       15          5   \n",
       "keyword_addendum shall become effective           0.0       22          7   \n",
       "keyword_addendum is part of                       0.0       35          9   \n",
       "keyword_duration of this addendum                 0.0       20          5   \n",
       "keyword_purpose of addendum                       0.0       16          3   \n",
       "keyword_this addendum                             0.0      128         22   \n",
       "keyword_this amendment                            0.0       80          7   \n",
       "regex_addendum                                    0.0       85          7   \n",
       "keyword_this amendment is entered into            0.0        2          0   \n",
       "keyword_this amendment is made and entered        0.0        6          0   \n",
       "keyword_purpose of amendment                      0.0        1          0   \n",
       "keyword_this addendum is entered into             0.0       13          0   \n",
       "\n",
       "                                            Emp. Acc.  \n",
       "keyword_amendment is part of                 0.000000  \n",
       "keyword_term of this amendment               0.000000  \n",
       "keyword_this addendum is made and entered    0.000000  \n",
       "keyword_amendment shall become effective     0.000000  \n",
       "keyword_this amendment is between            0.000000  \n",
       "keyword_this addendum is between             0.000000  \n",
       "keyword_duration of this amendment           0.000000  \n",
       "keyword_term of this addendum                0.750000  \n",
       "keyword_addendum shall become effective      0.758621  \n",
       "keyword_addendum is part of                  0.795455  \n",
       "keyword_duration of this addendum            0.800000  \n",
       "keyword_purpose of addendum                  0.842105  \n",
       "keyword_this addendum                        0.853333  \n",
       "keyword_this amendment                       0.919540  \n",
       "regex_addendum                               0.923913  \n",
       "keyword_this amendment is entered into       1.000000  \n",
       "keyword_this amendment is made and entered   1.000000  \n",
       "keyword_purpose of amendment                 1.000000  \n",
       "keyword_this addendum is entered into        1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "addendum_keywords = [\"this addendum\", \"this amendment\",\n",
    "                       \"addendum is part of\", \"amendment is part of\",\n",
    "                       \"term of this addendum\", \"term of this amendment\",\n",
    "                       \"this amendment is made and entered\", \"this addendum is made and entered\", \n",
    "                       \"this amendment is entered into\", \"this addendum is entered into\",\n",
    "                       \"this amendment is between\", \"this addendum is between\",\n",
    "                       \"duration of this addendum\", \"duration of this amendment\",\n",
    "                       \"purpose of amendment\", \"purpose of addendum\",\n",
    "                       \"addendum shall become effective\", \"amendment shall become effective\"]\n",
    "\n",
    "ABSTAIN = -1\n",
    "ADDENDUM = 0\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=ADDENDUM):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "labl_functions = []\n",
    "for key in addendum_keywords:\n",
    "    labl_functions.append(make_keyword_lf([key]))\n",
    "\n",
    "match = re.search(r\"(?:addendum|amendment) (?:is the (first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth|[0-9](st|nd|rd|th))|no.\\s?[0-9]|number (one|two|three|four|five|six|seven|eight|nine|ten|[0-9])|#\\s?[0-9])\", text)\n",
    "\n",
    "@labeling_function()\n",
    "def regex_addendum(x):\n",
    "    return ADDENDUM if re.search(r\"(?:addendum|amendment) (?:is the (first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth|[0-9](st|nd|rd|th))|no.\\s?[0-9]|number (one|two|three|four|five|six|seven|eight|nine|ten|[0-9])|#\\s?[0-9])\", x.text) else ABSTAIN\n",
    "    \n",
    "labl_functions.append(regex_addendum)\n",
    "print(labl_functions)\n",
    "\n",
    "applier = PandasLFApplier(lfs=labl_functions)\n",
    "L_train = applier.apply(df=df)\n",
    "\n",
    "#labels\n",
    "#y = df_addendum.label.values\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=labl_functions).lf_summary(y).sort_values(by='Emp. Acc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 1400/1400 [00:00<00:00, 9884.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabelingFunction keyword_mutual confidentiality, Preprocessors: [], LabelingFunction keyword_nondisclosure agreement, Preprocessors: [], LabelingFunction keyword_non disclosure agreement, Preprocessors: []]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>keyword_non disclosure agreement</td>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.102857</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_nondisclosure agreement</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword_mutual confidentiality</td>\n",
       "      <td>0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "keyword_non disclosure agreement  2      [2]  0.102857  0.039286        0.0   \n",
       "keyword_nondisclosure agreement   1      [2]  0.005714  0.000714        0.0   \n",
       "keyword_mutual confidentiality    0      [2]  0.059286  0.038571        0.0   \n",
       "\n",
       "                                  Correct  Incorrect  Emp. Acc.  \n",
       "keyword_non disclosure agreement       68         76   0.472222  \n",
       "keyword_nondisclosure agreement         4          4   0.500000  \n",
       "keyword_mutual confidentiality         81          2   0.975904  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "nda_keywords = ['mutual confidentiality','nondisclosure agreement', 'non disclosure agreement']\n",
    "\n",
    "ABSTAIN = -1\n",
    "NDA = 2\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=NDA):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "labl_functions = []\n",
    "for key in nda_keywords:\n",
    "    labl_functions.append(make_keyword_lf([key]))\n",
    "\n",
    "print(labl_functions)\n",
    "\n",
    "applier = PandasLFApplier(lfs=labl_functions)\n",
    "L_train = applier.apply(df=df)\n",
    "\n",
    "#labels\n",
    "#y = df_nda.label.values\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=labl_functions).lf_summary(y).sort_values(by='Emp. Acc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 1400/1400 [00:00<00:00, 18083.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>others_lookup</td>\n",
       "      <td>0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257</td>\n",
       "      <td>1143</td>\n",
       "      <td>0.183571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "others_lookup  0      [3]       1.0       0.0        0.0      257       1143   \n",
       "\n",
       "               Emp. Acc.  \n",
       "others_lookup   0.183571  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "ABSTAIN = -1\n",
    "Others = 3\n",
    "\n",
    "@labeling_function()\n",
    "def others_lookup(x):\n",
    "    if any(word not in x.text.lower() for word in list(set(msa_keywords + sow_keywords + nda_keywords + addendum_keywords))):\n",
    "        return Others\n",
    "    return ABSTAIN\n",
    "\n",
    "lfs=[others_lookup]\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df)\n",
    "\n",
    "#labels\n",
    "#y = df_nda.label.values\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary(y).sort_values(by='Emp. Acc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabelingFunction keyword_set forth section, Preprocessors: [], LabelingFunction keyword_meaning set forth, Preprocessors: [], LabelingFunction keyword_including without limitation, Preprocessors: [], LabelingFunction keyword_prior written consent, Preprocessors: [], LabelingFunction keyword_without prior written, Preprocessors: [], LabelingFunction keyword_intellectual industrial property, Preprocessors: [], LabelingFunction keyword_industrial property right, Preprocessors: [], LabelingFunction keyword_intellectual property right, Preprocessors: [], LabelingFunction keyword_privacy restricted data, Preprocessors: [], LabelingFunction keyword_prior written notice, Preprocessors: [], LabelingFunction keyword_force majeure event, Preprocessors: [], LabelingFunction keyword_subject matter hereof, Preprocessors: [], LabelingFunction keyword_confidential information, Preprocessors: [], LabelingFunction keyword_work product, Preprocessors: [], LabelingFunction keyword_shall deemed, Preprocessors: [], LabelingFunction keyword_disclosing party, Preprocessors: [], LabelingFunction keyword_without limitation, Preprocessors: [], LabelingFunction keyword_indemnified party, Preprocessors: [], LabelingFunction keyword_indemnifying party, Preprocessors: [], LabelingFunction keyword_applicable law, Preprocessors: [], LabelingFunction keyword_force majeure, Preprocessors: [], LabelingFunction keyword_trade secret, Preprocessors: [], LabelingFunction keyword_obligation agreement, Preprocessors: [], LabelingFunction keyword_intellectual industrial, Preprocessors: [], LabelingFunction keyword_statement work, Preprocessors: [], LabelingFunction keyword_sow, Preprocessors: [], LabelingFunction keyword_term sow, Preprocessors: [], LabelingFunction keyword_sow effective date, Preprocessors: [], LabelingFunction keyword_work sow, Preprocessors: [], LabelingFunction keyword_sow shall, Preprocessors: [], LabelingFunction keyword_sow consultant, Preprocessors: [], LabelingFunction keyword_sow term, Preprocessors: [], LabelingFunction keyword_service sow, Preprocessors: [], LabelingFunction keyword_sow project, Preprocessors: [], LabelingFunction keyword_defined sow, Preprocessors: [], LabelingFunction keyword_specified sow, Preprocessors: [], LabelingFunction keyword_outlined sow, Preprocessors: [], LabelingFunction keyword_msa sow, Preprocessors: [], LabelingFunction keyword_addendum sow, Preprocessors: [], LabelingFunction keyword_client sow, Preprocessors: [], LabelingFunction keyword_sow client, Preprocessors: [], LabelingFunction keyword_sow agreement, Preprocessors: [], LabelingFunction keyword_statement work effective, Preprocessors: [], LabelingFunction keyword_agreement statement work, Preprocessors: [], LabelingFunction keyword_addendum, Preprocessors: [], LabelingFunction keyword_amendment, Preprocessors: [], LabelingFunction keyword_book production, Preprocessors: [], LabelingFunction keyword_production health, Preprocessors: [], LabelingFunction keyword_agreement amendment, Preprocessors: [], LabelingFunction keyword_agreement addendum, Preprocessors: [], LabelingFunction keyword_addendum number, Preprocessors: [], LabelingFunction keyword_addendum executed, Preprocessors: [], LabelingFunction keyword_amendment agreement, Preprocessors: [], LabelingFunction keyword_sow subsequent, Preprocessors: [], LabelingFunction keyword_subsequent addendum, Preprocessors: [], LabelingFunction keyword_addendum made, Preprocessors: [], LabelingFunction keyword_amendment number, Preprocessors: [], LabelingFunction keyword_amendment date, Preprocessors: [], LabelingFunction keyword_amendment entered, Preprocessors: [], LabelingFunction keyword_amendment made, Preprocessors: [], LabelingFunction keyword_amendment executed, Preprocessors: [], LabelingFunction keyword_amendment term, Preprocessors: [], LabelingFunction keyword_amendment effective date, Preprocessors: [], LabelingFunction keyword_inconsistent contradictory term, Preprocessors: [], LabelingFunction keyword_addendum may executed, Preprocessors: [], LabelingFunction keyword_addendum made entered, Preprocessors: [], LabelingFunction keyword_effective date addendum, Preprocessors: [], LabelingFunction keyword_addendum statement work, Preprocessors: [], LabelingFunction keyword_amendment made entered, Preprocessors: [], LabelingFunction keyword_addendum effective date, Preprocessors: [], LabelingFunction keyword_effective date amendment, Preprocessors: [], LabelingFunction keyword_amend agreement, Preprocessors: [], LabelingFunction keyword_agreement amended, Preprocessors: [], LabelingFunction keyword_agreement hereby amended, Preprocessors: [], LabelingFunction keyword_service agreement amendment, Preprocessors: [], LabelingFunction keyword_mutual confidentiality, Preprocessors: [], LabelingFunction keyword_affiliated entity, Preprocessors: [], LabelingFunction keyword_agreement negotiation, Preprocessors: [], LabelingFunction keyword_disclosure hereunder, Preprocessors: [], LabelingFunction keyword_confidentiality confidential, Preprocessors: [], LabelingFunction keyword_protect confidentiality, Preprocessors: [], LabelingFunction keyword_mutual confidentiality agreement, Preprocessors: [], LabelingFunction keyword_disclosure confidential information, Preprocessors: [], LabelingFunction keyword_non disclosure agreement, Preprocessors: [], LabelingFunction keyword_non confidential basis, Preprocessors: [], LabelingFunction keyword_confidential information agent, Preprocessors: [], LabelingFunction keyword_confidentiality non disclosure, Preprocessors: [], LabelingFunction keyword_disclosing party prompt, Preprocessors: [], LabelingFunction keyword_notice intent terminate, Preprocessors: [], LabelingFunction others_lookup, Preprocessors: []]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "ABSTAIN = -1\n",
    "MSA = 1\n",
    "SOW = 4\n",
    "ADDENDUM = 0\n",
    "NDA = 2\n",
    "OTHERS = 3\n",
    "\n",
    "labl_functions = []\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "#===============MSA===================\n",
    "msa_keywords = ['set forth section', 'meaning set forth', 'including without limitation', \n",
    "                'prior written consent', 'without prior written', 'intellectual industrial property', \n",
    "                'industrial property right', 'intellectual property right',  'privacy restricted data', \n",
    "                'prior written notice', 'force majeure event',  'subject matter hereof', 'confidential information',\n",
    "                'work product', 'shall deemed', 'disclosing party', 'without limitation', 'indemnified party', \n",
    "                'indemnifying party', 'applicable law', 'force majeure', 'trade secret', 'obligation agreement', \n",
    "                'intellectual industrial']\n",
    "\n",
    "def make_keyword_lf_msa(keywords, label=MSA):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label))\n",
    "\n",
    "for key in msa_keywords:\n",
    "    labl_functions.append(make_keyword_lf_msa([key]))\n",
    "\n",
    "@labeling_function()\n",
    "def regex_agreement(x):\n",
    "    return MSA if re.search(r\"agreement (.+?) between (.+?) and (.+?)\", x.text) else ABSTAIN\n",
    "    \n",
    "#labl_functions.append(regex_agreement)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#===============SOW===================\n",
    "sow_keywords = ['statement work','sow','term sow','sow effective date', 'work sow', 'sow shall', 'sow consultant',\n",
    "                'sow term', 'service sow', 'sow project', 'defined sow','specified sow','outlined sow','msa sow',\n",
    "                'addendum sow', 'client sow','sow client', 'sow agreement', 'statement work effective', \n",
    "                'agreement statement work']\n",
    "\n",
    "def make_keyword_lf_sow(keywords, label=SOW):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "for key in sow_keywords:\n",
    "    labl_functions.append(make_keyword_lf_sow([key]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#===============ADDENDUM===================\n",
    "addendum_keywords = ['addendum', 'amendment', 'book production', 'production health', 'agreement amendment', \n",
    "                     'agreement addendum', 'addendum number', 'addendum executed', 'amendment agreement', 'sow subsequent', \n",
    "                     'subsequent addendum', 'addendum made', 'amendment number', 'amendment date', 'amendment entered', \n",
    "                     'amendment made', 'amendment executed', 'amendment term', 'amendment effective date', \n",
    "                     'inconsistent contradictory term', 'addendum may executed', 'addendum made entered', 'effective date addendum', \n",
    "                     'addendum statement work', 'amendment made entered', 'addendum effective date', \n",
    "                     'effective date amendment', 'amend agreement', 'agreement amended', 'agreement hereby amended', \n",
    "                     'service agreement amendment']\n",
    "\n",
    "def make_keyword_lf_addendum(keywords, label=ADDENDUM):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "for key in addendum_keywords:\n",
    "    labl_functions.append(make_keyword_lf_addendum([key]))\n",
    "\n",
    "@labeling_function()\n",
    "def regex_addendum(x):\n",
    "    return ADDENDUM if re.search(r\"(?:addendum|amendment) (?:is the (first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth|[0-9](st|nd|rd|th))|no.\\s?[0-9]|number (one|two|three|four|five|six|seven|eight|nine|ten|[0-9])|#\\s?[0-9])\", x.text) else ABSTAIN\n",
    "    \n",
    "#labl_functions.append(regex_addendum)\n",
    "\n",
    "\n",
    "\n",
    "#===============NDA===================\n",
    "nda_keywords = ['mutual confidentiality', 'affiliated entity', 'agreement negotiation', 'disclosure hereunder', \n",
    "                'confidentiality confidential', 'protect confidentiality', 'mutual confidentiality agreement', \n",
    "                'disclosure confidential information', 'non disclosure agreement', 'non confidential basis', \n",
    "                'confidential information agent', 'confidentiality non disclosure', 'disclosing party prompt', \n",
    "                'notice intent terminate']\n",
    "\n",
    "\n",
    "def make_keyword_lf_nda(keywords, label=NDA):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "for key in nda_keywords:\n",
    "    labl_functions.append(make_keyword_lf_nda([key]))\n",
    "    \n",
    "    \n",
    "\n",
    "#===============OTHERS===================\n",
    "@labeling_function()\n",
    "def others_lookup(x):\n",
    "    if all(word not in x.text.lower() for word in list(set(msa_keywords + sow_keywords + nda_keywords + addendum_keywords))):\n",
    "        return OTHERS\n",
    "    return ABSTAIN\n",
    "\n",
    "labl_functions.append(others_lookup)\n",
    "\n",
    "print(labl_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15467\n"
     ]
    }
   ],
   "source": [
    "path = '/home/user/Shyam/DATASET/classified_corpus_text/'\n",
    "\n",
    "docs = []\n",
    "filenames = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt') and file not in df.filename.values:\n",
    "            with open (os.path.join(root+'/'+file), encoding='utf8') as f:            \n",
    "                text = f.read()\n",
    "                text = preprocess(text)                            \n",
    "                docs.append(text)\n",
    "                filenames.append(file)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D05236.pdf.out.html.txt</td>\n",
       "      <td>dec 05 03 09 49a quim brown   ettiott 8645915...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D06496.pdf.out.html.txt</td>\n",
       "      <td>11 10 10 wed 04 14 fax 783 545.   38 colours ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D15596.pdf.out.html.txt</td>\n",
       "      <td>date   subject   wolters kluwer nv   zuidpool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D27186.pdf.out.html.txt</td>\n",
       "      <td>loch     woltexs kinwer busines   statement o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D12738.pdf.out.html.txt</td>\n",
       "      <td>amendment two   to the outsource services agr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                               text\n",
       "0  D05236.pdf.out.html.txt   dec 05 03 09 49a quim brown   ettiott 8645915...\n",
       "1  D06496.pdf.out.html.txt   11 10 10 wed 04 14 fax 783 545.   38 colours ...\n",
       "2  D15596.pdf.out.html.txt   date   subject   wolters kluwer nv   zuidpool...\n",
       "3  D27186.pdf.out.html.txt   loch     woltexs kinwer busines   statement o...\n",
       "4  D12738.pdf.out.html.txt   amendment two   to the outsource services agr..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(list(zip(filenames, docs)), columns=['filename','text'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split labelled data into valid and test sets\n",
    "import numpy as np\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "df_valid = df[msk]\n",
    "df_test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "print(len(df_valid))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([222, 391, 105, 218, 213])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid = df_valid.label.map({'Addendum': 0, 'MSA': 1, 'SOW': 4, 'NDA': 2, 'Others': 3})\n",
    "y_valid = np.array(y_valid)\n",
    "np.bincount(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56, 76, 29, 39, 51])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_test.label.map({'Addendum': 0, 'MSA': 1, 'SOW': 4, 'NDA': 2, 'Others': 3})\n",
    "y_test = np.array(y_test)\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_valid.drop('label', axis=1, inplace=True)\n",
    "df_test.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Labeling Functions to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "\n",
      "  0%|          | 0/15467 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 39/15467 [00:00<00:40, 384.24it/s]\u001b[A\n",
      "  0%|          | 77/15467 [00:00<00:41, 374.28it/s]\u001b[A\n",
      "  1%|          | 116/15467 [00:00<00:41, 372.02it/s]\u001b[A\n",
      "  1%|          | 158/15467 [00:00<00:39, 383.32it/s]\u001b[A\n",
      "  1%|▏         | 194/15467 [00:00<00:40, 375.79it/s]\u001b[A\n",
      "  1%|▏         | 229/15467 [00:00<00:41, 367.65it/s]\u001b[A\n",
      "  2%|▏         | 262/15467 [00:00<00:44, 344.39it/s]\u001b[A\n",
      "  2%|▏         | 304/15467 [00:00<00:42, 353.26it/s]\u001b[A\n",
      "  2%|▏         | 344/15467 [00:00<00:41, 365.69it/s]\u001b[A\n",
      "  2%|▏         | 380/15467 [00:01<00:45, 332.96it/s]\u001b[A\n",
      "  3%|▎         | 417/15467 [00:01<00:43, 343.22it/s]\u001b[A\n",
      "  3%|▎         | 455/15467 [00:01<00:42, 352.55it/s]\u001b[A\n",
      "  3%|▎         | 491/15467 [00:01<00:44, 335.60it/s]\u001b[A\n",
      "  3%|▎         | 525/15467 [00:01<00:44, 334.12it/s]\u001b[A\n",
      "  4%|▎         | 564/15467 [00:01<00:42, 348.85it/s]\u001b[A\n",
      "  4%|▍         | 600/15467 [00:01<00:42, 346.51it/s]\u001b[A\n",
      "  4%|▍         | 635/15467 [00:01<00:44, 331.70it/s]\u001b[A\n",
      "  4%|▍         | 669/15467 [00:01<00:45, 328.18it/s]\u001b[A\n",
      "  5%|▍         | 703/15467 [00:02<00:45, 326.56it/s]\u001b[A\n",
      "  5%|▍         | 738/15467 [00:02<00:44, 332.17it/s]\u001b[A\n",
      "  5%|▍         | 773/15467 [00:02<00:43, 337.10it/s]\u001b[A\n",
      "  5%|▌         | 810/15467 [00:02<00:42, 345.77it/s]\u001b[A\n",
      "  6%|▌         | 851/15467 [00:02<00:40, 362.33it/s]\u001b[A\n",
      "  6%|▌         | 894/15467 [00:02<00:38, 379.61it/s]\u001b[A\n",
      "  6%|▌         | 933/15467 [00:02<00:38, 376.69it/s]\u001b[A\n",
      "  6%|▋         | 974/15467 [00:02<00:37, 385.23it/s]\u001b[A\n",
      "  7%|▋         | 1022/15467 [00:02<00:35, 408.82it/s]\u001b[A\n",
      "  7%|▋         | 1064/15467 [00:02<00:35, 407.77it/s]\u001b[A\n",
      "  7%|▋         | 1106/15467 [00:03<00:37, 385.98it/s]\u001b[A\n",
      "  7%|▋         | 1148/15467 [00:03<00:36, 387.94it/s]\u001b[A\n",
      "  8%|▊         | 1189/15467 [00:03<00:36, 394.09it/s]\u001b[A\n",
      "  8%|▊         | 1229/15467 [00:03<00:37, 376.33it/s]\u001b[A\n",
      "  8%|▊         | 1267/15467 [00:03<00:38, 365.54it/s]\u001b[A\n",
      "  8%|▊         | 1306/15467 [00:03<00:38, 370.92it/s]\u001b[A\n",
      "  9%|▊         | 1345/15467 [00:03<00:37, 374.83it/s]\u001b[A\n",
      "  9%|▉         | 1383/15467 [00:03<00:37, 371.10it/s]\u001b[A\n",
      "  9%|▉         | 1421/15467 [00:03<00:38, 361.89it/s]\u001b[A\n",
      "  9%|▉         | 1458/15467 [00:04<00:40, 348.98it/s]\u001b[A\n",
      " 10%|▉         | 1498/15467 [00:04<00:38, 362.66it/s]\u001b[A\n",
      " 10%|▉         | 1543/15467 [00:04<00:36, 377.67it/s]\u001b[A\n",
      " 10%|█         | 1582/15467 [00:04<00:37, 369.40it/s]\u001b[A\n",
      " 10%|█         | 1620/15467 [00:04<00:38, 361.51it/s]\u001b[A\n",
      " 11%|█         | 1657/15467 [00:04<00:38, 362.51it/s]\u001b[A\n",
      " 11%|█         | 1694/15467 [00:04<00:38, 360.10it/s]\u001b[A\n",
      " 11%|█         | 1731/15467 [00:04<00:38, 355.10it/s]\u001b[A\n",
      " 11%|█▏        | 1767/15467 [00:04<00:41, 330.62it/s]\u001b[A\n",
      " 12%|█▏        | 1803/15467 [00:05<00:40, 337.91it/s]\u001b[A\n",
      " 12%|█▏        | 1838/15467 [00:05<00:40, 337.16it/s]\u001b[A\n",
      " 12%|█▏        | 1878/15467 [00:05<00:38, 352.63it/s]\u001b[A\n",
      " 12%|█▏        | 1920/15467 [00:05<00:36, 369.74it/s]\u001b[A\n",
      " 13%|█▎        | 1958/15467 [00:05<00:37, 364.30it/s]\u001b[A\n",
      " 13%|█▎        | 2000/15467 [00:05<00:35, 379.05it/s]\u001b[A\n",
      " 13%|█▎        | 2039/15467 [00:05<00:36, 363.60it/s]\u001b[A\n",
      " 13%|█▎        | 2076/15467 [00:05<00:36, 363.23it/s]\u001b[A\n",
      " 14%|█▎        | 2114/15467 [00:05<00:37, 359.59it/s]\u001b[A\n",
      " 14%|█▍        | 2151/15467 [00:05<00:38, 343.28it/s]\u001b[A\n",
      " 14%|█▍        | 2190/15467 [00:06<00:37, 355.41it/s]\u001b[A\n",
      " 14%|█▍        | 2226/15467 [00:06<00:40, 324.15it/s]\u001b[A\n",
      " 15%|█▍        | 2263/15467 [00:06<00:39, 336.63it/s]\u001b[A\n",
      " 15%|█▍        | 2298/15467 [00:06<00:39, 335.51it/s]\u001b[A\n",
      " 15%|█▌        | 2333/15467 [00:06<00:41, 315.18it/s]\u001b[A\n",
      " 15%|█▌        | 2366/15467 [00:06<00:44, 294.84it/s]\u001b[A\n",
      " 16%|█▌        | 2399/15467 [00:06<00:43, 302.90it/s]\u001b[A\n",
      " 16%|█▌        | 2430/15467 [00:06<00:44, 293.38it/s]\u001b[A\n",
      " 16%|█▌        | 2460/15467 [00:06<00:47, 274.87it/s]\u001b[A\n",
      " 16%|█▌        | 2489/15467 [00:07<00:50, 258.92it/s]\u001b[A\n",
      " 16%|█▋        | 2522/15467 [00:07<00:46, 275.79it/s]\u001b[A\n",
      " 16%|█▋        | 2551/15467 [00:07<00:48, 264.84it/s]\u001b[A\n",
      " 17%|█▋        | 2581/15467 [00:07<00:46, 274.42it/s]\u001b[A\n",
      " 17%|█▋        | 2617/15467 [00:07<00:43, 294.61it/s]\u001b[A\n",
      " 17%|█▋        | 2648/15467 [00:07<00:48, 266.18it/s]\u001b[A\n",
      " 17%|█▋        | 2682/15467 [00:07<00:45, 284.10it/s]\u001b[A\n",
      " 18%|█▊        | 2718/15467 [00:07<00:42, 301.89it/s]\u001b[A\n",
      " 18%|█▊        | 2750/15467 [00:07<00:41, 303.06it/s]\u001b[A\n",
      " 18%|█▊        | 2782/15467 [00:08<00:42, 298.72it/s]\u001b[A\n",
      " 18%|█▊        | 2813/15467 [00:08<00:43, 292.04it/s]\u001b[A\n",
      " 18%|█▊        | 2843/15467 [00:08<00:43, 293.50it/s]\u001b[A\n",
      " 19%|█▊        | 2873/15467 [00:08<00:44, 285.45it/s]\u001b[A\n",
      " 19%|█▉        | 2906/15467 [00:08<00:42, 292.86it/s]\u001b[A\n",
      " 19%|█▉        | 2938/15467 [00:08<00:41, 300.50it/s]\u001b[A\n",
      " 19%|█▉        | 2969/15467 [00:08<00:43, 288.64it/s]\u001b[A\n",
      " 19%|█▉        | 3002/15467 [00:08<00:42, 295.53it/s]\u001b[A\n",
      " 20%|█▉        | 3035/15467 [00:08<00:40, 304.62it/s]\u001b[A\n",
      " 20%|█▉        | 3069/15467 [00:09<00:39, 312.76it/s]\u001b[A\n",
      " 20%|██        | 3102/15467 [00:09<00:39, 311.29it/s]\u001b[A\n",
      " 20%|██        | 3134/15467 [00:09<00:40, 302.13it/s]\u001b[A\n",
      " 20%|██        | 3165/15467 [00:09<00:41, 296.45it/s]\u001b[A\n",
      " 21%|██        | 3195/15467 [00:09<00:44, 278.87it/s]\u001b[A\n",
      " 21%|██        | 3227/15467 [00:09<00:42, 287.90it/s]\u001b[A\n",
      " 21%|██        | 3263/15467 [00:09<00:40, 304.37it/s]\u001b[A\n",
      " 21%|██▏       | 3294/15467 [00:09<00:44, 273.44it/s]\u001b[A\n",
      " 22%|██▏       | 3326/15467 [00:09<00:42, 282.75it/s]\u001b[A\n",
      " 22%|██▏       | 3357/15467 [00:10<00:42, 286.47it/s]\u001b[A\n",
      " 22%|██▏       | 3387/15467 [00:10<00:42, 285.16it/s]\u001b[A\n",
      " 22%|██▏       | 3416/15467 [00:10<00:43, 275.46it/s]\u001b[A\n",
      " 22%|██▏       | 3453/15467 [00:10<00:40, 293.50it/s]\u001b[A\n",
      " 23%|██▎       | 3485/15467 [00:10<00:40, 297.76it/s]\u001b[A\n",
      " 23%|██▎       | 3517/15467 [00:10<00:39, 303.17it/s]\u001b[A\n",
      " 23%|██▎       | 3548/15467 [00:10<00:40, 294.41it/s]\u001b[A\n",
      " 23%|██▎       | 3578/15467 [00:10<00:40, 291.60it/s]\u001b[A\n",
      " 23%|██▎       | 3608/15467 [00:10<00:43, 271.11it/s]\u001b[A\n",
      " 24%|██▎       | 3644/15467 [00:11<00:40, 289.65it/s]\u001b[A\n",
      " 24%|██▍       | 3675/15467 [00:11<00:40, 293.78it/s]\u001b[A\n",
      " 24%|██▍       | 3705/15467 [00:11<00:42, 275.61it/s]\u001b[A\n",
      " 24%|██▍       | 3734/15467 [00:11<00:42, 277.76it/s]\u001b[A\n",
      " 24%|██▍       | 3764/15467 [00:11<00:42, 278.47it/s]\u001b[A\n",
      " 25%|██▍       | 3795/15467 [00:11<00:40, 286.97it/s]\u001b[A\n",
      " 25%|██▍       | 3824/15467 [00:11<00:41, 280.14it/s]\u001b[A\n",
      " 25%|██▍       | 3853/15467 [00:11<00:42, 276.36it/s]\u001b[A\n",
      " 25%|██▌       | 3881/15467 [00:11<00:42, 272.61it/s]\u001b[A\n",
      " 25%|██▌       | 3911/15467 [00:12<00:41, 279.35it/s]\u001b[A\n",
      " 25%|██▌       | 3940/15467 [00:12<00:42, 272.23it/s]\u001b[A\n",
      " 26%|██▌       | 3977/15467 [00:12<00:38, 295.09it/s]\u001b[A\n",
      " 26%|██▌       | 4013/15467 [00:12<00:36, 311.49it/s]\u001b[A\n",
      " 26%|██▌       | 4047/15467 [00:12<00:35, 318.00it/s]\u001b[A\n",
      " 26%|██▋       | 4080/15467 [00:12<00:36, 315.93it/s]\u001b[A\n",
      " 27%|██▋       | 4112/15467 [00:12<00:37, 300.11it/s]\u001b[A\n",
      " 27%|██▋       | 4143/15467 [00:12<00:37, 299.26it/s]\u001b[A\n",
      " 27%|██▋       | 4174/15467 [00:12<00:42, 263.64it/s]\u001b[A\n",
      " 27%|██▋       | 4207/15467 [00:13<00:40, 278.93it/s]\u001b[A\n",
      " 27%|██▋       | 4236/15467 [00:13<00:41, 273.68it/s]\u001b[A\n",
      " 28%|██▊       | 4267/15467 [00:13<00:41, 273.03it/s]\u001b[A\n",
      " 28%|██▊       | 4303/15467 [00:13<00:38, 293.50it/s]\u001b[A\n",
      " 28%|██▊       | 4336/15467 [00:13<00:36, 302.60it/s]\u001b[A\n",
      " 28%|██▊       | 4367/15467 [00:13<00:37, 293.78it/s]\u001b[A\n",
      " 28%|██▊       | 4397/15467 [00:13<00:39, 281.31it/s]\u001b[A\n",
      " 29%|██▊       | 4429/15467 [00:13<00:37, 290.96it/s]\u001b[A\n",
      " 29%|██▉       | 4459/15467 [00:13<00:38, 283.64it/s]\u001b[A\n",
      " 29%|██▉       | 4491/15467 [00:13<00:38, 287.88it/s]\u001b[A\n",
      " 29%|██▉       | 4525/15467 [00:14<00:36, 300.20it/s]\u001b[A\n",
      " 29%|██▉       | 4561/15467 [00:14<00:34, 315.90it/s]\u001b[A\n",
      " 30%|██▉       | 4594/15467 [00:14<00:35, 308.98it/s]\u001b[A\n",
      " 30%|██▉       | 4626/15467 [00:14<00:34, 312.13it/s]\u001b[A\n",
      " 30%|███       | 4661/15467 [00:14<00:33, 322.16it/s]\u001b[A\n",
      " 30%|███       | 4694/15467 [00:14<00:35, 306.66it/s]\u001b[A\n",
      " 31%|███       | 4725/15467 [00:14<00:37, 287.67it/s]\u001b[A\n",
      " 31%|███       | 4758/15467 [00:14<00:36, 296.66it/s]\u001b[A\n",
      " 31%|███       | 4789/15467 [00:14<00:36, 294.02it/s]\u001b[A\n",
      " 31%|███       | 4820/15467 [00:15<00:35, 295.77it/s]\u001b[A\n",
      " 31%|███▏      | 4852/15467 [00:15<00:35, 299.53it/s]\u001b[A\n",
      " 32%|███▏      | 4883/15467 [00:15<00:35, 296.81it/s]\u001b[A\n",
      " 32%|███▏      | 4914/15467 [00:15<00:35, 298.81it/s]\u001b[A\n",
      " 32%|███▏      | 4950/15467 [00:15<00:34, 305.46it/s]\u001b[A\n",
      " 32%|███▏      | 4981/15467 [00:15<00:35, 293.33it/s]\u001b[A\n",
      " 32%|███▏      | 5017/15467 [00:15<00:33, 310.23it/s]\u001b[A\n",
      " 33%|███▎      | 5049/15467 [00:15<00:34, 298.32it/s]\u001b[A\n",
      " 33%|███▎      | 5080/15467 [00:15<00:37, 276.03it/s]\u001b[A\n",
      " 33%|███▎      | 5112/15467 [00:16<00:36, 285.03it/s]\u001b[A\n",
      " 33%|███▎      | 5141/15467 [00:16<00:37, 276.44it/s]\u001b[A\n",
      " 33%|███▎      | 5173/15467 [00:16<00:35, 286.65it/s]\u001b[A\n",
      " 34%|███▎      | 5208/15467 [00:16<00:33, 302.80it/s]\u001b[A\n",
      " 34%|███▍      | 5239/15467 [00:16<00:38, 264.66it/s]\u001b[A\n",
      " 34%|███▍      | 5273/15467 [00:16<00:36, 278.75it/s]\u001b[A\n",
      " 34%|███▍      | 5310/15467 [00:16<00:33, 300.52it/s]\u001b[A\n",
      " 35%|███▍      | 5343/15467 [00:16<00:33, 303.76it/s]\u001b[A\n",
      " 35%|███▍      | 5375/15467 [00:16<00:35, 280.84it/s]\u001b[A\n",
      " 35%|███▍      | 5405/15467 [00:17<00:39, 256.42it/s]\u001b[A\n",
      " 35%|███▌      | 5439/15467 [00:17<00:36, 275.43it/s]\u001b[A\n",
      " 35%|███▌      | 5468/15467 [00:17<00:39, 256.25it/s]\u001b[A\n",
      " 36%|███▌      | 5497/15467 [00:17<00:37, 263.25it/s]\u001b[A\n",
      " 36%|███▌      | 5530/15467 [00:17<00:35, 279.54it/s]\u001b[A\n",
      " 36%|███▌      | 5560/15467 [00:17<00:34, 284.93it/s]\u001b[A\n",
      " 36%|███▌      | 5590/15467 [00:17<00:35, 281.56it/s]\u001b[A\n",
      " 36%|███▋      | 5620/15467 [00:17<00:35, 279.69it/s]\u001b[A\n",
      " 37%|███▋      | 5652/15467 [00:17<00:33, 289.65it/s]\u001b[A\n",
      " 37%|███▋      | 5682/15467 [00:18<00:33, 290.68it/s]\u001b[A\n",
      " 37%|███▋      | 5712/15467 [00:18<00:37, 260.17it/s]\u001b[A\n",
      " 37%|███▋      | 5743/15467 [00:18<00:35, 272.32it/s]\u001b[A\n",
      " 37%|███▋      | 5778/15467 [00:18<00:33, 290.04it/s]\u001b[A\n",
      " 38%|███▊      | 5811/15467 [00:18<00:32, 298.14it/s]\u001b[A\n",
      " 38%|███▊      | 5842/15467 [00:18<00:32, 299.78it/s]\u001b[A\n",
      " 38%|███▊      | 5873/15467 [00:18<00:32, 299.57it/s]\u001b[A\n",
      " 38%|███▊      | 5905/15467 [00:18<00:31, 305.10it/s]\u001b[A\n",
      " 38%|███▊      | 5940/15467 [00:18<00:30, 316.71it/s]\u001b[A\n",
      " 39%|███▊      | 5975/15467 [00:19<00:29, 325.81it/s]\u001b[A\n",
      " 39%|███▉      | 6010/15467 [00:19<00:28, 331.37it/s]\u001b[A\n",
      " 39%|███▉      | 6047/15467 [00:19<00:27, 339.55it/s]\u001b[A\n",
      " 39%|███▉      | 6082/15467 [00:19<00:28, 328.49it/s]\u001b[A\n",
      " 40%|███▉      | 6116/15467 [00:19<00:30, 304.00it/s]\u001b[A\n",
      " 40%|███▉      | 6147/15467 [00:19<00:30, 301.65it/s]\u001b[A\n",
      " 40%|███▉      | 6179/15467 [00:19<00:30, 303.82it/s]\u001b[A\n",
      " 40%|████      | 6215/15467 [00:19<00:29, 313.25it/s]\u001b[A\n",
      " 40%|████      | 6248/15467 [00:19<00:29, 314.51it/s]\u001b[A\n",
      " 41%|████      | 6280/15467 [00:19<00:29, 315.16it/s]\u001b[A\n",
      " 41%|████      | 6312/15467 [00:20<00:30, 301.34it/s]\u001b[A\n",
      " 41%|████      | 6343/15467 [00:20<00:30, 301.20it/s]\u001b[A\n",
      " 41%|████      | 6374/15467 [00:20<00:30, 298.79it/s]\u001b[A\n",
      " 41%|████▏     | 6409/15467 [00:20<00:29, 311.99it/s]\u001b[A\n",
      " 42%|████▏     | 6441/15467 [00:20<00:30, 299.03it/s]\u001b[A\n",
      " 42%|████▏     | 6479/15467 [00:20<00:28, 317.19it/s]\u001b[A\n",
      " 42%|████▏     | 6512/15467 [00:20<00:29, 298.67it/s]\u001b[A\n",
      " 42%|████▏     | 6543/15467 [00:20<00:29, 299.23it/s]\u001b[A\n",
      " 43%|████▎     | 6575/15467 [00:20<00:29, 304.09it/s]\u001b[A\n",
      " 43%|████▎     | 6606/15467 [00:21<00:30, 290.35it/s]\u001b[A\n",
      " 43%|████▎     | 6643/15467 [00:21<00:29, 301.89it/s]\u001b[A\n",
      " 43%|████▎     | 6675/15467 [00:21<00:28, 306.53it/s]\u001b[A\n",
      " 43%|████▎     | 6706/15467 [00:21<00:28, 306.66it/s]\u001b[A\n",
      " 44%|████▎     | 6740/15467 [00:21<00:27, 314.20it/s]\u001b[A\n",
      " 44%|████▍     | 6772/15467 [00:21<00:29, 293.78it/s]\u001b[A\n",
      " 44%|████▍     | 6802/15467 [00:21<00:29, 289.21it/s]\u001b[A\n",
      " 44%|████▍     | 6833/15467 [00:21<00:29, 294.40it/s]\u001b[A\n",
      " 44%|████▍     | 6863/15467 [00:21<00:29, 294.62it/s]\u001b[A\n",
      " 45%|████▍     | 6895/15467 [00:22<00:28, 300.21it/s]\u001b[A\n",
      " 45%|████▍     | 6926/15467 [00:22<00:28, 298.36it/s]\u001b[A\n",
      " 45%|████▍     | 6956/15467 [00:22<00:29, 288.97it/s]\u001b[A\n",
      " 45%|████▌     | 6989/15467 [00:22<00:28, 297.62it/s]\u001b[A\n",
      " 45%|████▌     | 7023/15467 [00:22<00:27, 307.31it/s]\u001b[A\n",
      " 46%|████▌     | 7054/15467 [00:22<00:28, 300.37it/s]\u001b[A\n",
      " 46%|████▌     | 7085/15467 [00:22<00:28, 295.77it/s]\u001b[A\n",
      " 46%|████▌     | 7115/15467 [00:22<00:31, 267.57it/s]\u001b[A\n",
      " 46%|████▌     | 7143/15467 [00:22<00:31, 266.68it/s]\u001b[A\n",
      " 46%|████▋     | 7171/15467 [00:23<00:35, 236.97it/s]\u001b[A\n",
      " 47%|████▋     | 7196/15467 [00:23<00:35, 232.16it/s]\u001b[A\n",
      " 47%|████▋     | 7221/15467 [00:23<00:35, 235.28it/s]\u001b[A\n",
      " 47%|████▋     | 7245/15467 [00:23<00:36, 224.89it/s]\u001b[A\n",
      " 47%|████▋     | 7270/15467 [00:23<00:36, 226.85it/s]\u001b[A\n",
      " 47%|████▋     | 7293/15467 [00:23<00:36, 221.69it/s]\u001b[A\n",
      " 47%|████▋     | 7316/15467 [00:23<00:37, 218.84it/s]\u001b[A\n",
      " 47%|████▋     | 7339/15467 [00:23<00:37, 218.79it/s]\u001b[A\n",
      " 48%|████▊     | 7362/15467 [00:23<00:38, 209.43it/s]\u001b[A\n",
      " 48%|████▊     | 7384/15467 [00:24<00:38, 210.54it/s]\u001b[A\n",
      " 48%|████▊     | 7407/15467 [00:24<00:37, 212.79it/s]\u001b[A\n",
      " 48%|████▊     | 7436/15467 [00:24<00:35, 229.06it/s]\u001b[A\n",
      " 48%|████▊     | 7463/15467 [00:24<00:33, 237.83it/s]\u001b[A\n",
      " 48%|████▊     | 7489/15467 [00:24<00:32, 242.08it/s]\u001b[A\n",
      " 49%|████▊     | 7514/15467 [00:24<00:33, 240.90it/s]\u001b[A\n",
      " 49%|████▊     | 7539/15467 [00:24<00:35, 223.64it/s]\u001b[A\n",
      " 49%|████▉     | 7566/15467 [00:24<00:33, 235.28it/s]\u001b[A\n",
      " 49%|████▉     | 7590/15467 [00:24<00:34, 231.39it/s]\u001b[A\n",
      " 49%|████▉     | 7615/15467 [00:25<00:33, 235.56it/s]\u001b[A\n",
      " 49%|████▉     | 7643/15467 [00:25<00:31, 246.94it/s]\u001b[A\n",
      " 50%|████▉     | 7669/15467 [00:25<00:32, 238.02it/s]\u001b[A\n",
      " 50%|████▉     | 7694/15467 [00:25<00:33, 235.08it/s]\u001b[A\n",
      " 50%|████▉     | 7718/15467 [00:25<00:34, 222.62it/s]\u001b[A\n",
      " 50%|█████     | 7741/15467 [00:25<00:39, 195.52it/s]\u001b[A\n",
      " 50%|█████     | 7766/15467 [00:25<00:36, 208.58it/s]\u001b[A\n",
      " 50%|█████     | 7791/15467 [00:25<00:35, 218.65it/s]\u001b[A\n",
      " 51%|█████     | 7819/15467 [00:25<00:32, 232.14it/s]\u001b[A\n",
      " 51%|█████     | 7843/15467 [00:26<00:36, 206.09it/s]\u001b[A\n",
      " 51%|█████     | 7865/15467 [00:26<00:36, 209.92it/s]\u001b[A\n",
      " 51%|█████     | 7887/15467 [00:26<00:40, 187.22it/s]\u001b[A\n",
      " 51%|█████     | 7910/15467 [00:26<00:38, 194.08it/s]\u001b[A\n",
      " 51%|█████▏    | 7931/15467 [00:26<00:39, 188.90it/s]\u001b[A\n",
      " 51%|█████▏    | 7951/15467 [00:26<00:40, 185.89it/s]\u001b[A\n",
      " 52%|█████▏    | 7976/15467 [00:26<00:37, 197.90it/s]\u001b[A\n",
      " 52%|█████▏    | 8001/15467 [00:26<00:35, 209.78it/s]\u001b[A\n",
      " 52%|█████▏    | 8024/15467 [00:26<00:34, 213.78it/s]\u001b[A\n",
      " 52%|█████▏    | 8046/15467 [00:27<00:37, 196.09it/s]\u001b[A\n",
      " 52%|█████▏    | 8076/15467 [00:27<00:33, 217.98it/s]\u001b[A\n",
      " 52%|█████▏    | 8100/15467 [00:27<00:33, 219.08it/s]\u001b[A\n",
      " 53%|█████▎    | 8126/15467 [00:27<00:32, 224.59it/s]\u001b[A\n",
      " 53%|█████▎    | 8150/15467 [00:27<00:32, 227.52it/s]\u001b[A\n",
      " 53%|█████▎    | 8177/15467 [00:27<00:30, 238.01it/s]\u001b[A\n",
      " 53%|█████▎    | 8202/15467 [00:27<00:34, 209.65it/s]\u001b[A\n",
      " 53%|█████▎    | 8224/15467 [00:27<00:34, 210.38it/s]\u001b[A\n",
      " 53%|█████▎    | 8251/15467 [00:28<00:33, 217.52it/s]\u001b[A\n",
      " 53%|█████▎    | 8274/15467 [00:28<00:33, 215.26it/s]\u001b[A\n",
      " 54%|█████▎    | 8298/15467 [00:28<00:32, 221.02it/s]\u001b[A\n",
      " 54%|█████▍    | 8321/15467 [00:28<00:34, 210.17it/s]\u001b[A\n",
      " 54%|█████▍    | 8343/15467 [00:28<00:33, 212.69it/s]\u001b[A\n",
      " 54%|█████▍    | 8370/15467 [00:28<00:31, 225.92it/s]\u001b[A\n",
      " 54%|█████▍    | 8393/15467 [00:28<00:31, 227.02it/s]\u001b[A\n",
      " 54%|█████▍    | 8423/15467 [00:28<00:29, 239.64it/s]\u001b[A\n",
      " 55%|█████▍    | 8448/15467 [00:28<00:30, 228.86it/s]\u001b[A\n",
      " 55%|█████▍    | 8472/15467 [00:28<00:30, 229.04it/s]\u001b[A\n",
      " 55%|█████▍    | 8500/15467 [00:29<00:28, 240.54it/s]\u001b[A\n",
      " 55%|█████▌    | 8525/15467 [00:29<00:28, 240.09it/s]\u001b[A\n",
      " 55%|█████▌    | 8550/15467 [00:29<00:31, 216.97it/s]\u001b[A\n",
      " 55%|█████▌    | 8573/15467 [00:29<00:31, 217.34it/s]\u001b[A\n",
      " 56%|█████▌    | 8596/15467 [00:29<00:32, 211.65it/s]\u001b[A\n",
      " 56%|█████▌    | 8619/15467 [00:29<00:32, 213.71it/s]\u001b[A\n",
      " 56%|█████▌    | 8641/15467 [00:29<00:32, 212.33it/s]\u001b[A\n",
      " 56%|█████▌    | 8664/15467 [00:29<00:31, 213.91it/s]\u001b[A\n",
      " 56%|█████▌    | 8686/15467 [00:29<00:33, 203.07it/s]\u001b[A\n",
      " 56%|█████▋    | 8711/15467 [00:30<00:31, 213.40it/s]\u001b[A\n",
      " 56%|█████▋    | 8735/15467 [00:30<00:30, 219.99it/s]\u001b[A\n",
      " 57%|█████▋    | 8758/15467 [00:30<00:33, 202.46it/s]\u001b[A\n",
      " 57%|█████▋    | 8782/15467 [00:30<00:31, 211.26it/s]\u001b[A\n",
      " 57%|█████▋    | 8805/15467 [00:30<00:30, 216.07it/s]\u001b[A\n",
      " 57%|█████▋    | 8827/15467 [00:30<00:30, 216.89it/s]\u001b[A\n",
      " 57%|█████▋    | 8850/15467 [00:30<00:30, 220.39it/s]\u001b[A\n",
      " 57%|█████▋    | 8873/15467 [00:30<00:30, 218.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 8896/15467 [00:30<00:31, 210.21it/s]\u001b[A\n",
      " 58%|█████▊    | 8918/15467 [00:31<00:31, 206.99it/s]\u001b[A\n",
      " 58%|█████▊    | 8939/15467 [00:31<00:31, 205.86it/s]\u001b[A\n",
      " 58%|█████▊    | 8964/15467 [00:31<00:30, 213.18it/s]\u001b[A\n",
      " 58%|█████▊    | 8986/15467 [00:31<00:31, 203.86it/s]\u001b[A\n",
      " 58%|█████▊    | 9007/15467 [00:31<00:31, 205.28it/s]\u001b[A\n",
      " 58%|█████▊    | 9028/15467 [00:31<00:31, 205.40it/s]\u001b[A\n",
      " 59%|█████▊    | 9049/15467 [00:31<00:31, 203.45it/s]\u001b[A\n",
      " 59%|█████▊    | 9071/15467 [00:31<00:30, 206.75it/s]\u001b[A\n",
      " 59%|█████▉    | 9092/15467 [00:31<00:32, 195.56it/s]\u001b[A\n",
      " 59%|█████▉    | 9122/15467 [00:32<00:29, 214.67it/s]\u001b[A\n",
      " 59%|█████▉    | 9148/15467 [00:32<00:27, 226.45it/s]\u001b[A\n",
      " 59%|█████▉    | 9172/15467 [00:32<00:28, 219.63it/s]\u001b[A\n",
      " 59%|█████▉    | 9195/15467 [00:32<00:28, 218.27it/s]\u001b[A\n",
      " 60%|█████▉    | 9222/15467 [00:32<00:27, 224.19it/s]\u001b[A\n",
      " 60%|█████▉    | 9255/15467 [00:32<00:25, 247.07it/s]\u001b[A\n",
      " 60%|██████    | 9281/15467 [00:32<00:25, 245.26it/s]\u001b[A\n",
      " 60%|██████    | 9311/15467 [00:32<00:24, 252.24it/s]\u001b[A\n",
      " 60%|██████    | 9347/15467 [00:32<00:22, 276.71it/s]\u001b[A\n",
      " 61%|██████    | 9376/15467 [00:32<00:21, 277.29it/s]\u001b[A\n",
      " 61%|██████    | 9405/15467 [00:33<00:21, 278.08it/s]\u001b[A\n",
      " 61%|██████    | 9437/15467 [00:33<00:20, 289.36it/s]\u001b[A\n",
      " 61%|██████    | 9467/15467 [00:33<00:21, 284.67it/s]\u001b[A\n",
      " 61%|██████▏   | 9496/15467 [00:33<00:21, 272.07it/s]\u001b[A\n",
      " 62%|██████▏   | 9524/15467 [00:33<00:22, 269.64it/s]\u001b[A\n",
      " 62%|██████▏   | 9559/15467 [00:33<00:20, 288.80it/s]\u001b[A\n",
      " 62%|██████▏   | 9593/15467 [00:33<00:19, 300.79it/s]\u001b[A\n",
      " 62%|██████▏   | 9624/15467 [00:33<00:19, 299.42it/s]\u001b[A\n",
      " 62%|██████▏   | 9657/15467 [00:33<00:18, 307.86it/s]\u001b[A\n",
      " 63%|██████▎   | 9689/15467 [00:34<00:19, 301.24it/s]\u001b[A\n",
      " 63%|██████▎   | 9726/15467 [00:34<00:17, 318.97it/s]\u001b[A\n",
      " 63%|██████▎   | 9759/15467 [00:34<00:17, 319.78it/s]\u001b[A\n",
      " 63%|██████▎   | 9792/15467 [00:34<00:18, 307.62it/s]\u001b[A\n",
      " 64%|██████▎   | 9824/15467 [00:34<00:18, 306.79it/s]\u001b[A\n",
      " 64%|██████▎   | 9855/15467 [00:34<00:18, 302.66it/s]\u001b[A\n",
      " 64%|██████▍   | 9887/15467 [00:34<00:18, 306.39it/s]\u001b[A\n",
      " 64%|██████▍   | 9918/15467 [00:34<00:20, 271.14it/s]\u001b[A\n",
      " 64%|██████▍   | 9946/15467 [00:34<00:20, 263.81it/s]\u001b[A\n",
      " 65%|██████▍   | 9981/15467 [00:35<00:19, 284.74it/s]\u001b[A\n",
      " 65%|██████▍   | 10016/15467 [00:35<00:18, 299.31it/s]\u001b[A\n",
      " 65%|██████▍   | 10050/15467 [00:35<00:17, 309.95it/s]\u001b[A\n",
      " 65%|██████▌   | 10082/15467 [00:35<00:18, 295.38it/s]\u001b[A\n",
      " 65%|██████▌   | 10116/15467 [00:35<00:17, 302.95it/s]\u001b[A\n",
      " 66%|██████▌   | 10147/15467 [00:35<00:17, 304.52it/s]\u001b[A\n",
      " 66%|██████▌   | 10178/15467 [00:35<00:17, 305.33it/s]\u001b[A\n",
      " 66%|██████▌   | 10211/15467 [00:35<00:16, 312.32it/s]\u001b[A\n",
      " 66%|██████▌   | 10243/15467 [00:35<00:19, 274.60it/s]\u001b[A\n",
      " 66%|██████▋   | 10272/15467 [00:36<00:18, 276.31it/s]\u001b[A\n",
      " 67%|██████▋   | 10301/15467 [00:36<00:18, 277.67it/s]\u001b[A\n",
      " 67%|██████▋   | 10330/15467 [00:36<00:19, 263.19it/s]\u001b[A\n",
      " 67%|██████▋   | 10357/15467 [00:36<00:19, 261.89it/s]\u001b[A\n",
      " 67%|██████▋   | 10388/15467 [00:36<00:18, 274.48it/s]\u001b[A\n",
      " 67%|██████▋   | 10421/15467 [00:36<00:17, 289.03it/s]\u001b[A\n",
      " 68%|██████▊   | 10451/15467 [00:36<00:17, 286.71it/s]\u001b[A\n",
      " 68%|██████▊   | 10486/15467 [00:36<00:16, 302.49it/s]\u001b[A\n",
      " 68%|██████▊   | 10523/15467 [00:36<00:15, 319.47it/s]\u001b[A\n",
      " 68%|██████▊   | 10556/15467 [00:36<00:15, 307.72it/s]\u001b[A\n",
      " 68%|██████▊   | 10588/15467 [00:37<00:15, 308.41it/s]\u001b[A\n",
      " 69%|██████▊   | 10620/15467 [00:37<00:15, 303.27it/s]\u001b[A\n",
      " 69%|██████▉   | 10653/15467 [00:37<00:15, 310.28it/s]\u001b[A\n",
      " 69%|██████▉   | 10690/15467 [00:37<00:14, 325.73it/s]\u001b[A\n",
      " 69%|██████▉   | 10723/15467 [00:37<00:15, 311.10it/s]\u001b[A\n",
      " 70%|██████▉   | 10755/15467 [00:37<00:15, 305.54it/s]\u001b[A\n",
      " 70%|██████▉   | 10789/15467 [00:37<00:14, 312.56it/s]\u001b[A\n",
      " 70%|██████▉   | 10821/15467 [00:37<00:14, 313.57it/s]\u001b[A\n",
      " 70%|███████   | 10853/15467 [00:37<00:15, 301.02it/s]\u001b[A\n",
      " 70%|███████   | 10884/15467 [00:38<00:15, 299.94it/s]\u001b[A\n",
      " 71%|███████   | 10918/15467 [00:38<00:14, 310.50it/s]\u001b[A\n",
      " 71%|███████   | 10953/15467 [00:38<00:14, 320.98it/s]\u001b[A\n",
      " 71%|███████   | 10986/15467 [00:38<00:14, 309.11it/s]\u001b[A\n",
      " 71%|███████   | 11018/15467 [00:38<00:14, 309.97it/s]\u001b[A\n",
      " 71%|███████▏  | 11050/15467 [00:38<00:14, 305.21it/s]\u001b[A\n",
      " 72%|███████▏  | 11081/15467 [00:38<00:14, 301.75it/s]\u001b[A\n",
      " 72%|███████▏  | 11112/15467 [00:38<00:14, 302.15it/s]\u001b[A\n",
      " 72%|███████▏  | 11144/15467 [00:38<00:14, 305.85it/s]\u001b[A\n",
      " 72%|███████▏  | 11182/15467 [00:38<00:13, 324.66it/s]\u001b[A\n",
      " 73%|███████▎  | 11215/15467 [00:39<00:13, 308.05it/s]\u001b[A\n",
      " 73%|███████▎  | 11254/15467 [00:39<00:12, 328.16it/s]\u001b[A\n",
      " 73%|███████▎  | 11288/15467 [00:39<00:12, 327.33it/s]\u001b[A\n",
      " 73%|███████▎  | 11324/15467 [00:39<00:12, 335.60it/s]\u001b[A\n",
      " 73%|███████▎  | 11358/15467 [00:39<00:12, 321.59it/s]\u001b[A\n",
      " 74%|███████▎  | 11391/15467 [00:39<00:13, 299.19it/s]\u001b[A\n",
      " 74%|███████▍  | 11428/15467 [00:39<00:12, 316.21it/s]\u001b[A\n",
      " 74%|███████▍  | 11461/15467 [00:39<00:12, 309.82it/s]\u001b[A\n",
      " 74%|███████▍  | 11496/15467 [00:39<00:12, 320.83it/s]\u001b[A\n",
      " 75%|███████▍  | 11533/15467 [00:40<00:11, 333.21it/s]\u001b[A\n",
      " 75%|███████▍  | 11572/15467 [00:40<00:11, 347.83it/s]\u001b[A\n",
      " 75%|███████▌  | 11608/15467 [00:40<00:11, 325.54it/s]\u001b[A\n",
      " 75%|███████▌  | 11642/15467 [00:40<00:11, 329.45it/s]\u001b[A\n",
      " 75%|███████▌  | 11676/15467 [00:40<00:11, 322.81it/s]\u001b[A\n",
      " 76%|███████▌  | 11709/15467 [00:40<00:12, 306.23it/s]\u001b[A\n",
      " 76%|███████▌  | 11741/15467 [00:40<00:12, 305.79it/s]\u001b[A\n",
      " 76%|███████▌  | 11778/15467 [00:40<00:11, 321.87it/s]\u001b[A\n",
      " 76%|███████▋  | 11812/15467 [00:40<00:11, 324.61it/s]\u001b[A\n",
      " 77%|███████▋  | 11845/15467 [00:41<00:11, 318.88it/s]\u001b[A\n",
      " 77%|███████▋  | 11878/15467 [00:41<00:12, 296.36it/s]\u001b[A\n",
      " 77%|███████▋  | 11913/15467 [00:41<00:11, 309.28it/s]\u001b[A\n",
      " 77%|███████▋  | 11945/15467 [00:41<00:11, 308.39it/s]\u001b[A\n",
      " 77%|███████▋  | 11982/15467 [00:41<00:10, 323.77it/s]\u001b[A\n",
      " 78%|███████▊  | 12015/15467 [00:41<00:11, 312.15it/s]\u001b[A\n",
      " 78%|███████▊  | 12047/15467 [00:41<00:11, 304.57it/s]\u001b[A\n",
      " 78%|███████▊  | 12083/15467 [00:41<00:10, 319.05it/s]\u001b[A\n",
      " 78%|███████▊  | 12116/15467 [00:41<00:10, 317.92it/s]\u001b[A\n",
      " 79%|███████▊  | 12150/15467 [00:42<00:10, 322.47it/s]\u001b[A\n",
      " 79%|███████▉  | 12183/15467 [00:42<00:10, 322.97it/s]\u001b[A\n",
      " 79%|███████▉  | 12216/15467 [00:42<00:10, 318.90it/s]\u001b[A\n",
      " 79%|███████▉  | 12249/15467 [00:42<00:10, 319.74it/s]\u001b[A\n",
      " 79%|███████▉  | 12282/15467 [00:42<00:10, 306.47it/s]\u001b[A\n",
      " 80%|███████▉  | 12315/15467 [00:42<00:10, 310.77it/s]\u001b[A\n",
      " 80%|███████▉  | 12349/15467 [00:42<00:09, 318.26it/s]\u001b[A\n",
      " 80%|████████  | 12381/15467 [00:42<00:09, 309.49it/s]\u001b[A\n",
      " 80%|████████  | 12413/15467 [00:42<00:09, 309.00it/s]\u001b[A\n",
      " 80%|████████  | 12445/15467 [00:42<00:10, 286.27it/s]\u001b[A\n",
      " 81%|████████  | 12479/15467 [00:43<00:09, 298.95it/s]\u001b[A\n",
      " 81%|████████  | 12510/15467 [00:43<00:10, 287.23it/s]\u001b[A\n",
      " 81%|████████  | 12540/15467 [00:43<00:10, 284.37it/s]\u001b[A\n",
      " 81%|████████▏ | 12573/15467 [00:43<00:09, 296.31it/s]\u001b[A\n",
      " 81%|████████▏ | 12603/15467 [00:43<00:09, 291.46it/s]\u001b[A\n",
      " 82%|████████▏ | 12637/15467 [00:43<00:09, 301.73it/s]\u001b[A\n",
      " 82%|████████▏ | 12670/15467 [00:43<00:09, 309.32it/s]\u001b[A\n",
      " 82%|████████▏ | 12705/15467 [00:43<00:08, 320.30it/s]\u001b[A\n",
      " 82%|████████▏ | 12738/15467 [00:43<00:08, 310.56it/s]\u001b[A\n",
      " 83%|████████▎ | 12770/15467 [00:44<00:08, 303.35it/s]\u001b[A\n",
      " 83%|████████▎ | 12801/15467 [00:44<00:09, 290.72it/s]\u001b[A\n",
      " 83%|████████▎ | 12831/15467 [00:44<00:09, 284.96it/s]\u001b[A\n",
      " 83%|████████▎ | 12862/15467 [00:44<00:08, 290.79it/s]\u001b[A\n",
      " 83%|████████▎ | 12895/15467 [00:44<00:08, 301.13it/s]\u001b[A\n",
      " 84%|████████▎ | 12931/15467 [00:44<00:08, 315.05it/s]\u001b[A\n",
      " 84%|████████▍ | 12963/15467 [00:44<00:07, 315.57it/s]\u001b[A\n",
      " 84%|████████▍ | 12995/15467 [00:44<00:08, 302.33it/s]\u001b[A\n",
      " 84%|████████▍ | 13031/15467 [00:44<00:07, 316.12it/s]\u001b[A\n",
      " 84%|████████▍ | 13068/15467 [00:45<00:07, 324.44it/s]\u001b[A\n",
      " 85%|████████▍ | 13104/15467 [00:45<00:07, 327.07it/s]\u001b[A\n",
      " 85%|████████▍ | 13138/15467 [00:45<00:07, 329.76it/s]\u001b[A\n",
      " 85%|████████▌ | 13172/15467 [00:45<00:07, 321.30it/s]\u001b[A\n",
      " 85%|████████▌ | 13205/15467 [00:45<00:08, 279.18it/s]\u001b[A\n",
      " 86%|████████▌ | 13238/15467 [00:45<00:07, 292.25it/s]\u001b[A\n",
      " 86%|████████▌ | 13269/15467 [00:45<00:07, 281.95it/s]\u001b[A\n",
      " 86%|████████▌ | 13298/15467 [00:45<00:07, 283.84it/s]\u001b[A\n",
      " 86%|████████▌ | 13330/15467 [00:45<00:07, 293.04it/s]\u001b[A\n",
      " 86%|████████▋ | 13360/15467 [00:46<00:07, 288.82it/s]\u001b[A\n",
      " 87%|████████▋ | 13392/15467 [00:46<00:06, 296.86it/s]\u001b[A\n",
      " 87%|████████▋ | 13422/15467 [00:46<00:06, 296.83it/s]\u001b[A\n",
      " 87%|████████▋ | 13459/15467 [00:46<00:06, 315.15it/s]\u001b[A\n",
      " 87%|████████▋ | 13491/15467 [00:46<00:06, 313.85it/s]\u001b[A\n",
      " 87%|████████▋ | 13523/15467 [00:46<00:06, 311.12it/s]\u001b[A\n",
      " 88%|████████▊ | 13559/15467 [00:46<00:05, 322.25it/s]\u001b[A\n",
      " 88%|████████▊ | 13594/15467 [00:46<00:05, 327.26it/s]\u001b[A\n",
      " 88%|████████▊ | 13627/15467 [00:46<00:05, 323.14it/s]\u001b[A\n",
      " 88%|████████▊ | 13660/15467 [00:46<00:05, 320.38it/s]\u001b[A\n",
      " 89%|████████▊ | 13693/15467 [00:47<00:05, 313.17it/s]\u001b[A\n",
      " 89%|████████▉ | 13728/15467 [00:47<00:05, 321.54it/s]\u001b[A\n",
      " 89%|████████▉ | 13761/15467 [00:47<00:05, 317.26it/s]\u001b[A\n",
      " 89%|████████▉ | 13793/15467 [00:47<00:05, 313.84it/s]\u001b[A\n",
      " 89%|████████▉ | 13825/15467 [00:47<00:05, 280.12it/s]\u001b[A\n",
      " 90%|████████▉ | 13862/15467 [00:47<00:05, 299.75it/s]\u001b[A\n",
      " 90%|████████▉ | 13894/15467 [00:47<00:05, 304.36it/s]\u001b[A\n",
      " 90%|█████████ | 13926/15467 [00:47<00:05, 294.28it/s]\u001b[A\n",
      " 90%|█████████ | 13956/15467 [00:47<00:05, 277.31it/s]\u001b[A\n",
      " 90%|█████████ | 13991/15467 [00:48<00:05, 294.83it/s]\u001b[A\n",
      " 91%|█████████ | 14027/15467 [00:48<00:04, 310.44it/s]\u001b[A\n",
      " 91%|█████████ | 14063/15467 [00:48<00:04, 322.35it/s]\u001b[A\n",
      " 91%|█████████ | 14098/15467 [00:48<00:04, 329.40it/s]\u001b[A\n",
      " 91%|█████████▏| 14135/15467 [00:48<00:03, 338.20it/s]\u001b[A\n",
      " 92%|█████████▏| 14172/15467 [00:48<00:03, 344.48it/s]\u001b[A\n",
      " 92%|█████████▏| 14208/15467 [00:48<00:03, 348.23it/s]\u001b[A\n",
      " 92%|█████████▏| 14247/15467 [00:48<00:03, 359.47it/s]\u001b[A\n",
      " 92%|█████████▏| 14286/15467 [00:48<00:03, 366.11it/s]\u001b[A\n",
      " 93%|█████████▎| 14323/15467 [00:48<00:03, 366.43it/s]\u001b[A\n",
      " 93%|█████████▎| 14361/15467 [00:49<00:02, 369.93it/s]\u001b[A\n",
      " 93%|█████████▎| 14400/15467 [00:49<00:02, 375.69it/s]\u001b[A\n",
      " 93%|█████████▎| 14438/15467 [00:49<00:02, 374.45it/s]\u001b[A\n",
      " 94%|█████████▎| 14476/15467 [00:49<00:02, 362.07it/s]\u001b[A\n",
      " 94%|█████████▍| 14513/15467 [00:49<00:02, 362.16it/s]\u001b[A\n",
      " 94%|█████████▍| 14552/15467 [00:49<00:02, 368.88it/s]\u001b[A\n",
      " 94%|█████████▍| 14589/15467 [00:49<00:02, 361.67it/s]\u001b[A\n",
      " 95%|█████████▍| 14626/15467 [00:49<00:02, 358.06it/s]\u001b[A\n",
      " 95%|█████████▍| 14666/15467 [00:49<00:02, 367.85it/s]\u001b[A\n",
      " 95%|█████████▌| 14704/15467 [00:49<00:02, 369.99it/s]\u001b[A\n",
      " 95%|█████████▌| 14742/15467 [00:50<00:02, 354.55it/s]\u001b[A\n",
      " 96%|█████████▌| 14780/15467 [00:50<00:01, 361.69it/s]\u001b[A\n",
      " 96%|█████████▌| 14820/15467 [00:50<00:01, 369.77it/s]\u001b[A\n",
      " 96%|█████████▌| 14858/15467 [00:50<00:01, 365.71it/s]\u001b[A\n",
      " 96%|█████████▋| 14895/15467 [00:50<00:01, 363.19it/s]\u001b[A\n",
      " 97%|█████████▋| 14934/15467 [00:50<00:01, 367.96it/s]\u001b[A\n",
      " 97%|█████████▋| 14972/15467 [00:50<00:01, 369.69it/s]\u001b[A\n",
      " 97%|█████████▋| 15010/15467 [00:50<00:01, 366.65it/s]\u001b[A\n",
      " 97%|█████████▋| 15047/15467 [00:50<00:01, 355.63it/s]\u001b[A\n",
      " 98%|█████████▊| 15084/15467 [00:51<00:01, 357.35it/s]\u001b[A\n",
      " 98%|█████████▊| 15120/15467 [00:51<00:00, 356.74it/s]\u001b[A\n",
      " 98%|█████████▊| 15157/15467 [00:51<00:00, 357.85it/s]\u001b[A\n",
      " 98%|█████████▊| 15195/15467 [00:51<00:00, 363.86it/s]\u001b[A\n",
      " 98%|█████████▊| 15232/15467 [00:51<00:00, 364.16it/s]\u001b[A\n",
      " 99%|█████████▊| 15270/15467 [00:51<00:00, 366.59it/s]\u001b[A\n",
      " 99%|█████████▉| 15308/15467 [00:51<00:00, 369.86it/s]\u001b[A\n",
      " 99%|█████████▉| 15348/15467 [00:51<00:00, 372.47it/s]\u001b[A\n",
      " 99%|█████████▉| 15386/15467 [00:51<00:00, 361.36it/s]\u001b[A\n",
      "100%|█████████▉| 15423/15467 [00:51<00:00, 363.73it/s]\u001b[A\n",
      "100%|██████████| 15467/15467 [00:52<00:00, 296.83it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/1149 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 49/1149 [00:00<00:02, 488.85it/s]\u001b[A\n",
      "  7%|▋         | 82/1149 [00:00<00:02, 426.47it/s]\u001b[A\n",
      " 11%|█         | 122/1149 [00:00<00:02, 414.36it/s]\u001b[A\n",
      " 15%|█▌        | 175/1149 [00:00<00:02, 443.19it/s]\u001b[A\n",
      " 18%|█▊        | 210/1149 [00:00<00:02, 405.42it/s]\u001b[A\n",
      " 22%|██▏       | 252/1149 [00:00<00:02, 407.66it/s]\u001b[A\n",
      " 25%|██▌       | 289/1149 [00:00<00:02, 377.94it/s]\u001b[A\n",
      " 29%|██▊       | 329/1149 [00:00<00:02, 380.03it/s]\u001b[A\n",
      " 32%|███▏      | 366/1149 [00:00<00:02, 339.04it/s]\u001b[A\n",
      " 35%|███▍      | 400/1149 [00:01<00:02, 317.08it/s]\u001b[A\n",
      " 38%|███▊      | 432/1149 [00:01<00:02, 317.51it/s]\u001b[A\n",
      " 40%|████      | 464/1149 [00:01<00:02, 253.37it/s]\u001b[A\n",
      " 43%|████▎     | 492/1149 [00:01<00:02, 225.94it/s]\u001b[A\n",
      " 45%|████▍     | 517/1149 [00:01<00:02, 212.24it/s]\u001b[A\n",
      " 47%|████▋     | 540/1149 [00:01<00:02, 215.40it/s]\u001b[A\n",
      " 49%|████▉     | 563/1149 [00:01<00:02, 210.54it/s]\u001b[A\n",
      " 51%|█████     | 585/1149 [00:02<00:02, 194.41it/s]\u001b[A\n",
      " 53%|█████▎    | 606/1149 [00:02<00:03, 179.77it/s]\u001b[A\n",
      " 54%|█████▍    | 625/1149 [00:02<00:02, 182.37it/s]\u001b[A\n",
      " 56%|█████▋    | 648/1149 [00:02<00:02, 193.12it/s]\u001b[A\n",
      " 58%|█████▊    | 668/1149 [00:02<00:02, 191.26it/s]\u001b[A\n",
      " 60%|█████▉    | 688/1149 [00:02<00:02, 183.43it/s]\u001b[A\n",
      " 62%|██████▏   | 708/1149 [00:02<00:02, 186.04it/s]\u001b[A\n",
      " 63%|██████▎   | 727/1149 [00:02<00:02, 173.84it/s]\u001b[A\n",
      " 65%|██████▍   | 745/1149 [00:02<00:02, 169.31it/s]\u001b[A\n",
      " 67%|██████▋   | 766/1149 [00:03<00:02, 179.51it/s]\u001b[A\n",
      " 68%|██████▊   | 785/1149 [00:03<00:02, 177.50it/s]\u001b[A\n",
      " 70%|███████   | 807/1149 [00:03<00:01, 185.34it/s]\u001b[A\n",
      " 72%|███████▏  | 828/1149 [00:03<00:01, 190.98it/s]\u001b[A\n",
      " 74%|███████▍  | 855/1149 [00:03<00:01, 207.25it/s]\u001b[A\n",
      " 77%|███████▋  | 881/1149 [00:03<00:01, 220.38it/s]\u001b[A\n",
      " 79%|███████▉  | 911/1149 [00:03<00:00, 238.16it/s]\u001b[A\n",
      " 81%|████████▏ | 936/1149 [00:03<00:00, 241.33it/s]\u001b[A\n",
      " 84%|████████▍ | 965/1149 [00:03<00:00, 254.05it/s]\u001b[A\n",
      " 87%|████████▋ | 995/1149 [00:03<00:00, 261.81it/s]\u001b[A\n",
      " 89%|████████▉ | 1022/1149 [00:04<00:00, 264.00it/s]\u001b[A\n",
      " 92%|█████████▏| 1052/1149 [00:04<00:00, 273.75it/s]\u001b[A\n",
      " 95%|█████████▍| 1091/1149 [00:04<00:00, 292.52it/s]\u001b[A\n",
      "100%|██████████| 1149/1149 [00:04<00:00, 259.53it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "#Apply the label functions to the train and valid sets\n",
    "applier = PandasLFApplier(lfs=labl_functions)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_valid = applier.apply(df=df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>Polarity</b>: The set of unique labels this LF outputs (excluding abstains) <br>\n",
    "<li><b>Coverage</b>: The fraction of the dataset the LF labels<br>\n",
    "<li><b>Overlaps</b>: The fraction of the dataset where this LF and at least one other LF label<br>\n",
    "<li><b>Conflicts</b>: The fraction of the dataset where this LF and at least one other LF label and disagree<br>\n",
    "<li><b>Correct</b>: The number of data points this LF labels correctly (if gold labels are provided)<br>\n",
    "<li><b>Incorrect</b>: The number of data points this LF labels incorrectly (if gold labels are provided)<br>\n",
    "<li><b>Empirical Accuracy</b>: The empirical accuracy of this LF (if gold labels are provided)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LFAnalysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5182a0a30eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Check the performance of label functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#LFAnalysis(L=L_train, lfs=labl_functions).lf_summary().sort_values(by='Coverage')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLFAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabl_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlf_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Emp. Acc.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LFAnalysis' is not defined"
     ]
    }
   ],
   "source": [
    "#Check the performance of label functions\n",
    "#LFAnalysis(L=L_train, lfs=labl_functions).lf_summary().sort_values(by='Coverage')\n",
    "LFAnalysis(L=L_valid, lfs=labl_functions).lf_summary(y_valid).sort_values(by='Emp. Acc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3, ..., 3, 3, 3],\n",
       "       [3, 3, 3, ..., 3, 3, 3],\n",
       "       [3, 3, 3, ..., 3, 3, 3],\n",
       "       ...,\n",
       "       [3, 1, 3, ..., 2, 3, 2],\n",
       "       [3, 1, 3, ..., 2, 3, 2],\n",
       "       [3, 1, 3, ..., 2, 3, 2]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Label Voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-bf5022bfcfe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmajority_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMajorityLabelVoter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmajority_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/snorkel/labeling/model/label_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, L, return_probs, tie_break_policy)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \"\"\"\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mY_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mY_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtie_break_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_probs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/snorkel/labeling/model/baselines.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, L)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                     \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mY_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mY_p\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mY_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = LabelModel(cardinality=5, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=500, lr=0.001, log_freq=50, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy:     65.7%\n"
     ]
    }
   ],
   "source": [
    "label_model_acc = label_model.score(L=L_valid, Y=y_valid)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter unlabelled data points\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99960711e-01, 5.38259622e-08, 1.48756887e-08, 8.32677404e-08,\n",
       "        3.91373277e-05],\n",
       "       [1.91601912e-05, 9.89331344e-01, 4.60149692e-05, 4.28054425e-05,\n",
       "        1.05606757e-02],\n",
       "       [2.37080628e-01, 2.37636745e-01, 2.87086446e-02, 3.87869451e-02,\n",
       "        4.57787038e-01],\n",
       "       ...,\n",
       "       [6.62925075e-15, 9.99943659e-01, 5.63410096e-05, 4.24924936e-14,\n",
       "        3.63681216e-18],\n",
       "       [6.62925075e-15, 9.99943659e-01, 5.63410096e-05, 4.24924936e-14,\n",
       "        3.63681216e-18],\n",
       "       [6.62925075e-15, 9.99943659e-01, 5.63410096e-05, 4.24924936e-14,\n",
       "        3.63681216e-18]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_train_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import names\n",
    "from snorkel.augmentation import transformation_function\n",
    "\n",
    "# Pregenerate some random person names to replace existing ones with\n",
    "# for the transformation strategies below\n",
    "replacement_names = [names.get_full_name() for _ in range(50)]\n",
    "\n",
    "\n",
    "# Replace a random named entity with a different entity of the same type.\n",
    "@transformation_function(pre=[spacy])\n",
    "def change_person(x):\n",
    "    person_names = [ent.text for ent in x.doc.ents if ent.label_ == \"ORG\"]\n",
    "    # If there is at least one person name, replace a random one. Else return None.\n",
    "    if person_names:\n",
    "        name_to_replace = np.random.choice(person_names)\n",
    "        replacement_name = np.random.choice(replacement_names)\n",
    "        x.text = x.text.replace(name_to_replace, replacement_name)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Swap two adjectives at random.\n",
    "@transformation_function(pre=[spacy])\n",
    "def swap_adjectives(x):\n",
    "    adjective_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"ADJ\"]\n",
    "    # Check that there are at least two adjectives to swap.\n",
    "    if len(adjective_idxs) >= 2:\n",
    "        idx1, idx2 = sorted(np.random.choice(adjective_idxs, 2, replace=False))\n",
    "        # Swap tokens in positions idx1 and idx2.\n",
    "        x.text = \" \".join(\n",
    "            [\n",
    "                x.doc[:idx1].text,\n",
    "                x.doc[idx2].text,\n",
    "                x.doc[1 + idx1 : idx2].text,\n",
    "                x.doc[idx1].text,\n",
    "                x.doc[1 + idx2 :].text,\n",
    "            ]\n",
    "        )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "\n",
    "def get_synonym(word, pos=None):\n",
    "    \"\"\"Get synonym for word given its part-of-speech (pos).\"\"\"\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    # Return None if wordnet has no synsets (synonym sets) for this word and pos.\n",
    "    if synsets:\n",
    "        words = [lemma.name() for lemma in synsets[0].lemmas()]\n",
    "        if words[0].lower() != word.lower():  # Skip if synonym is same as word.\n",
    "            # Multi word synonyms in wordnet use '_' as a separator e.g. reckon_with. Replace it with space.\n",
    "            return words[0].replace(\"_\", \" \")\n",
    "\n",
    "\n",
    "def replace_token(spacy_doc, idx, replacement):\n",
    "    \"\"\"Replace token in position idx with replacement.\"\"\"\n",
    "    return \" \".join([spacy_doc[:idx].text, replacement, spacy_doc[1 + idx :].text])\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_verb_with_synonym(x):\n",
    "    # Get indices of verb tokens in sentence.\n",
    "    verb_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"VERB\"]\n",
    "    if verb_idxs:\n",
    "        # Pick random verb idx to replace.\n",
    "        #idx = np.random.choice(verb_idxs)\n",
    "        for idx in verb_idxs:\n",
    "            synonym = get_synonym(x.doc[idx].text, pos=\"v\")\n",
    "            # If there's a valid verb synonym, replace it. Otherwise, return None.\n",
    "            if synonym:\n",
    "                x.text = replace_token(x.doc, idx, synonym)\n",
    "        return x\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_noun_with_synonym(x):\n",
    "    # Get indices of noun tokens in sentence.\n",
    "    noun_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"NOUN\"]\n",
    "    if noun_idxs:\n",
    "        # Pick random noun idx to replace.\n",
    "        #idx = np.random.choice(noun_idxs)\n",
    "        for idx in noun_idxs:\n",
    "            synonym = get_synonym(x.doc[idx].text, pos=\"n\")\n",
    "            # If there's a valid noun synonym, replace it. Otherwise, return None.\n",
    "            if synonym:\n",
    "                x.text = replace_token(x.doc, idx, synonym)\n",
    "        return x\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_adjective_with_synonym(x):\n",
    "    # Get indices of adjective tokens in sentence.\n",
    "    adjective_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"ADJ\"]\n",
    "    if adjective_idxs:\n",
    "        # Pick random adjective idx to replace.\n",
    "        #idx = np.random.choice(adjective_idxs)\n",
    "        for idx in adjective_idxs:\n",
    "            synonym = get_synonym(x.doc[idx].text, pos=\"a\")\n",
    "            # If there's a valid adjective synonym, replace it. Otherwise, return None.\n",
    "            if synonym:\n",
    "                x.text = replace_token(x.doc, idx, synonym)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [\n",
    "    change_person,\n",
    "    swap_adjectives,\n",
    "    replace_verb_with_synonym,\n",
    "    replace_noun_with_synonym,\n",
    "    replace_adjective_with_synonym,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preview_tfs\n",
    "\n",
    "df_transformed = preview_tfs(df_train, tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    as   aquatic management agreement   this agreement  proposal  19453 dated 6 21 2005  is made betwean aquagenix and customer    kings highway industrial park   7305 commercial circle   kings highway commercial park   ft. pierce  fl 34954  772  342 1935   both customer and aquagenix agree to the following terms and conditions    i  general conditions    aquagenix will provide aquatic management services on behalf of the customer in accordance with   the terms and conditions of this agreement at the following aquatic site s     2 retention pond and canals tocated in ft. pierce  fl.   2. contract term    the term of this agreement shall be 1 year s  or as otherwise provided by contract addendum.   3. contract services    customer agrees to pay aquagenix the following amounts during the term of this agreement for thase   specific water management services.   algae and aquatic plant contro  included   border grass and brush control to water s edge included   water testing  see addendum 13a  included   bacteria treatment included   aquatics consulting included   fish stocking  bass and bream  optional   management reporting included   biological control agent permit applications  triploid grass carp  mosquito fish  included   total annual program investment annual   4 620.00 monthly   385.00   1 inspections pec month with treatment as necessary    tdplold grass carp stocking subject to required approval of fish wildilfe conservation commission   .    374 n. killian or   a  b  lake park  fl 33408   created for kings highway industrial park  561  881 1201   fax  561  981 1293   agtononls ig a subtointy of darqgaiy braiter inc.    on    manag   scheduled visits   january 1 february 4 march 1 aprtt 4 may 1 dune 4   july 1 august 7 september 1 ostobar 1 november 4 bacember 1   4. starting date    the starting day of this agreement is the first day of the month in which services are first provided without   regard to the actual days uniess otherwise agreed to in writing  by both parties. services shall be   continuous without interruption.   u   schedule of payment     385.00 shall be due and payable upon execution of this agreement  the balance shall be payable in   advance as outlined in paragraph 3 above. customer agrees to pay aquagenix within thirty  30  days   after date of invoice at aquagenix s home office in hazleton  pa. failure to pay any amount when due   shall constitute a default under this agreement.   6. limited offer    the offer contained in this agnsament is valid for thirty  30  days only and must be returned to our office   for acceptance within that period  if not accepted within that time  the offer shail be void    7. safety    aquagenix agrees to use specialized equipment and products  which in its sole discretion  will provide safe   and effective results for the specific site s         address change    in the event that aquagenix or customer undergoes a change in address  notification to the other   party shall be made by first class mail. written instructions including the new address and telephone   number wilt be enciosed in the noilfication     . termination procedure    this agreement may be terminated by either party with sixty  60  days written notice. notification must be   sent by certified mail  retum receipt requested  to aquagenix  100 n conahan dr  hazleton  pa 18201.   aquagenix reserves the right  under special circumstances  to initiate surcharges relating to extraordinary   price increases of water treatrnent producis.   8.  date of termination  will be dafined as  two  2  months after the last day of the month in which  notice   of cancellation  was received by aquagenix in accordance with paragraphs 9b and 9c    b. in the event that your account is not settled in full at the same time as your cancellation letier is   received  aquagenix will continue to bill you until the contract expires. settlement in full includes   payment for one months service after the end of the month in which the cancellation letter i  received   by aquagenix.   c. payment in full shall be defined as payment to aquagenix through the effective  date of termination    as determined by the procedure outlined above in paragraphs 9a and 9b.   1974 n  kilhan or   4   b. lake park  fi 99463   created for kings highway industrial park  361  681 1291    fax  861  a8t 1293   aguagania i   auhalulary of ooangalo grainnr  ine    10. insurance    aquagenix agrees to maintain  at its sole expense  the following insurance coverage  worker s   compensation  general liability  automobile liability  property and casualty  excese liability and   business interruption coverage. upon written request  customer may be listed as an  additional   insured  at no exina charge. a certificate of insurance will be provided at the customer s request.   11. automatle renewal    uniess other wise agreed upon by both parties  this agreement shail automatically renew for a term equal   to its original term  unless a  notice of cancellation  has been received as outlined in paragraph 9. the   contract amount may be adjusted at a rate of 4  increase per year on the anniversary date of this   agreement. unless otherwise agreed to in writing  by both parties  services shall be continuous without   interruption.   12  default    if customer defaults on any provision of this agreement  customer hereby agrees that aquagenix   may at its sole discretion seek any or all of the following remedies    a. termination of this agreement. in this event  customer agrees to make immediate payment of the   total contract amount through the end of its term  less previously paid payments  as fiquidated and   agreed upon damage.   b. imposition of  collections charge  for monies due. if this action is deemed necessary  in the sole   judgement of aquagenix  customer agrees to pay aquagenix s reasonable attomey fees fincluding   those on appeal   court costs  collection costs and alt other expenses incurred by aquagenix resulting   from this collection activity.   c. filing of a mechanics lien on property for all monies due plus interest  costs and attomeys fees.   13. addenda    a. water testing and bacteria monitoring shall be conducted at the sole discretion of aquagenix for the   specific purpose of improving the aquatic weed control program results.   b. work as requested by customer such as trash clean up  physical culting and or plant removal and   other manual maintenance may be performed by our staff. extra work will be invoiced separately at our   current hourly equipment and labor rates.   14  contract documents    this agreement constitutes the entire agreement of aquagenix and the customer. in the event that   any portion of this agreement shall be held invalid or unenforceable  the remaining portions of this   agreement shail be binding upon both parties. no oral or written modification of the terms contained   herein snalipe valid unless made in writing and accepted by an authorized agent of both aquagenix and   cust .   sie. wile me atk   customer     28  qs     date   1374 n. kilkan on   4   b  lake park  ft 39403   created for kings highway industrial park   81  861 1291    fax  561  981 1203   aaeganis 18 a aubsidiory af daangalo bromern  inc    atx of florida   7205 commercial circle   ft pierce  fl 34951   attn  mr. steve willett   mr. willett    as per our recent conversation    am writing you to clarify which areas are   to be included in your aquatic maintaince contract. based on the diagrams  and   on the site walk thru  the areas to be treated include the primary retention pond    the retention channel leading from the east to the west towards the retention   pond  and the smaller channel crossing from the north to the south. as was also   discussed  the small retention ditch that was constructed along the perimeter of   the atx lot and the adjacent lot will be included. selective herbicide treatments   will be applied to the retention ditch to eliminate noxious weeds  while still   retaining a desired level of aesthetics.   will be contacting you regarding the   pricing for the remaining projects for the property s association  and do not   expect any un reasonablie delays. if   may be of further assistance  please do not   hesitate to cail.   regards    ere milby     eric malloy   sales manager  wpb treasure coast   deangelo brothers inc.  aquagenix   5605 florida mining boulevard south  building 200  suite 201 206  jacksonville  florida 32257    904  262 2001    fax  904  262 0010   aquagenix is a subsidiary of deangele brothers  inc.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed['Original Text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    as   aquatic management agreement   this agreement  proposal  19453 dated 6 21 2005  is made betwean aquagenix and customer    kings highway industrial park   7305 commercial circle   kings highway commercial park   ft. pierce  fl 34954  772  342 1935   both customer and aquagenix agree to the following terms and conditions    i  general conditions    aquagenix will provide aquatic management services on behalf of the customer in accordance with   the terms and conditions of this agreement at the following aquatic site s     2 retention pond and canals tocated in ft. pierce  fl.   2. contract term    the term of this agreement shall be 1 year s  or as otherwise provided by contract addendum.   3. contract services    customer agrees to pay aquagenix the following amounts during the term of this agreement for thase   specific water management services.   algae and aquatic plant contro  included   border grass and brush control to water s edge included   water testing  see addendum 13a  included   bacteria treatment included   aquatics consulting included   fish stocking  bass and bream  optional   management reporting included   biological control agent permit applications  triploid grass carp  mosquito fish  included   total annual program investment annual   4 620.00 monthly   385.00   1 inspections pec month with treatment as necessary    tdplold grass carp stocking subject to required approval of fish wildilfe conservation commission   .    374 n. killian or   a  b  lake park  fl 33408   created for kings highway industrial park  561  881 1201   fax  561  981 1293   agtononls ig a subtointy of darqgaiy braiter inc.    on    manag   scheduled visits   january 1 february 4 march 1 aprtt 4 may 1 dune 4   july 1 august 7 september 1 ostobar 1 november 4 bacember 1   4. starting date    the starting day of this agreement is the first day of the month in which services are first provided without   regard to the actual days uniess otherwise agreed to in writing  by both parties. services shall be   continuous without interruption.   u   schedule of payment     385.00 shall be due and payable upon execution of this agreement  the balance shall be payable in   advance as outlined in paragraph 3 above. customer agrees to pay aquagenix within thirty  30  days   after date of invoice at aquagenix s home office in hazleton  pa. failure to pay any amount when due   shall constitute a default under this agreement.   6. limited offer    the offer contained in this agnsament is valid for thirty  30  days only and must be returned to our office   for acceptance within that period  if not accepted within that time  the offer shail be void    7. safety    aquagenix agrees to use specialized equipment and products  which in its sole discretion  will provide safe   and effective results for the specific site s         address change    in the event that aquagenix or customer undergoes a change in address  notification to the other   party shall be made by first class mail. written instructions including the new address and telephone   number wilt be enciosed in the noilfication     . termination procedure    this agreement may be terminated by either party with sixty  60  days written notice. notification must be   sent by certified mail  retum receipt requested  to aquagenix  100 n conahan dr  hazleton  pa 18201.   aquagenix reserves the right  under special circumstances  to initiate surcharges relating to extraordinary   price increases of water treatrnent producis.   8.  date of termination  will be dafined as  two  2  months after the last day of the month in which  notice   of cancellation  was received by aquagenix in accordance with paragraphs 9b and 9c    b. in the event that your account is not settled in full at the same time as your cancellation letier is   received  aquagenix will continue to bill you until the contract expires. settlement in full includes   payment for one months service after the end of the month in which the cancellation letter i  received   by aquagenix.   c. payment in full shall be defined as payment to aquagenix through the effective  date of termination    as determined by the procedure outlined above in paragraphs 9a and 9b.   1974 n  kilhan or   4   b. lake park  fi 99463   created for kings highway industrial park  361  681 1291    fax  861  a8t 1293   aguagania i   auhalulary of ooangalo grainnr  ine    10. insurance    aquagenix agrees to maintain  at its sole expense  the following insurance coverage  worker s   compensation  general liability  automobile liability  property and casualty  excese liability and   business interruption coverage. upon written request  customer may be listed as an  additional   insured  at no exina charge. a certificate of insurance will be provided at the customer s request.   11. automatle renewal    uniess other wise agreed upon by both parties  this agreement shail automatically renew for a term equal   to its original term  unless a  notice of cancellation  has been received as outlined in paragraph 9. the   contract amount may be adjusted at a rate of 4  increase per year on the anniversary date of this   agreement. unless otherwise agreed to in writing  by both parties  services shall be continuous without   interruption.   12  default    if customer defaults on any provision of this agreement  customer hereby agrees that aquagenix   may at its sole discretion seek any or all of the following remedies    a. termination of this agreement. in this event  customer agrees to make immediate payment of the   total contract amount through the end of its term  less previously paid payments  as fiquidated and   agreed upon damage.   b. imposition of  collections charge  for monies due. if this action is deemed necessary  in the sole   judgement of aquagenix  customer agrees to pay aquagenix s reasonable attomey fees fincluding   those on appeal   court costs  collection costs and alt other expenses incurred by aquagenix resulting   from this collection activity.   c. filing of a mechanics lien on property for all monies due plus interest  costs and attomeys fees.   13. addenda    a. water testing and bacteria monitoring shall be conducted at the sole discretion of aquagenix for the   specific purpose of improving the aquatic weed control program results.   b. work as requested by customer such as trash clean up  physical culting and or plant removal and   other manual maintenance may be performed by our staff. extra work will be invoiced separately at our   current hourly equipment and labor rates.   14  contract documents    this agreement constitutes the entire agreement of aquagenix and the customer. in the event that   any portion of this agreement shall be held invalid or unenforceable  the remaining portions of this   agreement shail be binding upon both parties. no oral or written modification of the terms contained   herein snalipe valid unless made in writing and accepted by an authorized agent of both aquagenix and   cust .   sie. wile me atk   customer     28  qs     date   1374 n. kilkan on   4   b  lake park  ft 39403   created for kings highway industrial park   81  861 1291    fax  561  981 1203   aaeganis 18 a aubsidiory af daangalo bromern  inc    atx of florida   7205 commercial circle   ft pierce  fl 34951   attn  mr. steve willett   mr. willett    as per our recent conversation    am writing you to clarify which areas are   to be included in your aquatic maintaince contract. based on the diagrams  and   on the site walk thru  the areas to be treated include the primary retention pond    the retention channel leading from the east to the west towards the retention   pond  and the smaller channel crossing from the north to the south. as was also   discussed  the small retention ditch that was constructed along the perimeter of   the atx lot and the adjacent lot will be included. selective herbicide treatments   will be applied to the retention ditch to eliminate noxious weeds  while still   retaining a desired level of aesthetics.   will be contacting you regarding the   pricing for the remaining projects for the property s association  and do not   expect any un reasonablie delays. if   may be of further assistance  please do not   hesitate to cail.   regards    ere milby     eric malloy   sales manager  wpb treasure coast   deangelo brothers inc.  aquagenix   5605 florida mining boulevard south  building 200  suite 201 206  jacksonville  florida 32257    904  262 2001    fax  904  262 0010   aquagenix is a subsidiary of deangele brothers   Iraqi National Congress .'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed['Transformed Text'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4830, 24735,  5392, ...,  5177,  9938, 14648],\n",
       "        [17671, 18627, 18627, ...,  9237, 18571, 20356],\n",
       "        [27032, 24379, 12929, ...,  4981, 16644, 21820],\n",
       "        ...,\n",
       "        [   28,  3480, 28369, ..., 23453, 26165, 11300],\n",
       "        [   28,  3480,  4830, ..., 29175, 27595, 16315],\n",
       "        [ 4112, 15864, 12108, ...,  3570, 23453, 26165]]),)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15467 samples, validate on 1149 samples\n",
      "Epoch 1/25\n",
      "15467/15467 - 6s - loss: 0.0820 - acc: 0.9984 - val_loss: -5.1287e+01 - val_acc: 0.3403\n",
      "Epoch 2/25\n",
      "15467/15467 - 5s - loss: 2.1218e-06 - acc: 1.0000 - val_loss: -5.8763e+01 - val_acc: 0.3403\n",
      "Epoch 3/25\n",
      "15467/15467 - 6s - loss: 7.1212e-07 - acc: 1.0000 - val_loss: -6.4099e+01 - val_acc: 0.3403\n",
      "Epoch 4/25\n",
      "15467/15467 - 6s - loss: 3.3950e-07 - acc: 1.0000 - val_loss: -6.7853e+01 - val_acc: 0.3403\n",
      "Epoch 5/25\n",
      "15467/15467 - 6s - loss: 1.9863e-07 - acc: 1.0000 - val_loss: -7.0690e+01 - val_acc: 0.3403\n",
      "Epoch 6/25\n",
      "Restoring model weights from the end of the best epoch.\n",
      "15467/15467 - 5s - loss: 1.3119e-07 - acc: 1.0000 - val_loss: -7.2955e+01 - val_acc: 0.3403\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabb5cf02e8>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import featurize_df_tokens, get_keras_lstm, get_keras_early_stopping\n",
    "\n",
    "X_train = featurize_df_tokens(df_train)\n",
    "#X_train_augmented = featurize_df_tokens(df_train_augmented)\n",
    "X_valid = featurize_df_tokens(df_valid)\n",
    "X_test = featurize_df_tokens(df_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train,\n",
    "#Y_train,\n",
    "X_valid=X_valid,\n",
    "Y_valid=y_valid,\n",
    "X_test=X_test,\n",
    "Y_test=y_test,\n",
    "num_buckets=30000\n",
    "\n",
    "# Define a vanilla LSTM model with Keras\n",
    "lstm_model = get_keras_lstm(num_buckets)\n",
    "lstm_model.fit(\n",
    "    X_train,\n",
    "    #Y_train,\n",
    "    epochs=25,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    callbacks=[get_keras_early_stopping(5)],\n",
    "    verbose=2,\n",
    ")\n",
    "#preds_test = lstm_model.predict(X_test)[:, 0] > 0.5\n",
    "#print((preds_test == Y_test).mean())\n",
    "\n",
    "\n",
    "#acc_augmented = train_and_test(X_train_augmented, Y_train_augmented)\n",
    "#acc_original = train_and_test(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

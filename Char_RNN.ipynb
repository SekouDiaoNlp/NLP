{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Char_RNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/pskshyam/NLP/blob/master/Char_RNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BYsUiuHuMTUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kf64dICTMzII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ]
    },
    {
      "metadata": {
        "id": "TAode9CVNMmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c1b9a496-13a4-4e35-95cc-2a7503690267"
      },
      "cell_type": "code",
      "source": [
        "!wget -O Pride_and_Prejudice.txt http://www.gutenberg.org/files/1342/1342-0.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-01 08:04:54--  http://www.gutenberg.org/files/1342/1342-0.txt\r\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 724725 (708K) [text/plain]\n",
            "Saving to: ‘Pride_and_Prejudice.txt’\n",
            "\n",
            "Pride_and_Prejudice 100%[===================>] 707.74K   907KB/s    in 0.8s    \n",
            "\n",
            "2018-06-01 08:04:55 (907 KB/s) - ‘Pride_and_Prejudice.txt’ saved [724725/724725]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "40s2yLL6MwCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6854527f-e71a-45e2-ec90-433b98bf6d70"
      },
      "cell_type": "code",
      "source": [
        "book_text = open('Pride_and_Prejudice.txt', encoding='utf8').read()\n",
        "print(len(book_text)) #total characters in the book, not words"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "704190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nLbsHCrbNoWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build Tokenizer"
      ]
    },
    {
      "metadata": {
        "id": "DanaNaEENlnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer(char_level=True)\n",
        "t.fit_on_texts(book_text) #Each unique character is assigned with an index number. There are total of 86 unique characters."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPoBg4jKN2_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Number of unique characters"
      ]
    },
    {
      "metadata": {
        "id": "SBoYp5JXN1Oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "984f1bc5-f22d-4257-c330-a11e3ee04a40"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(t.word_index)\n",
        "vocab_size"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "OeC9mqlfN9FP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert Characters to Numbers"
      ]
    },
    {
      "metadata": {
        "id": "ncN7kxxqN8Ms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8e610fc-7fd9-4ed9-9a3a-6cc612540010"
      },
      "cell_type": "code",
      "source": [
        "book_num = t.texts_to_sequences(book_text)\n",
        "number_chars = len(book_num)\n",
        "number_chars"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "704190"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Hconzt8eOKdx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build Input and Output"
      ]
    },
    {
      "metadata": {
        "id": "tHXmdggZOJM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "input_data = []\n",
        "output_data = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBFOgOJbOVTV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Input and output container\n",
        "> Input data will have sequences with 100 characters\n",
        "\n",
        "> Output data will have one character which comes after 100 characters in the input data"
      ]
    },
    {
      "metadata": {
        "id": "yoFd6asvOeu7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, number_chars - sequence_length): #0 to (704190-100)\n",
        "    input_seq = book_num[i : i + sequence_length] #0:100, 1:101, 2:102, ...\n",
        "    output_seq = book_num[i + sequence_length] #100, 101, 102, ...\n",
        "    input_data.append(input_seq)\n",
        "    output_data.append(output_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3YzKu_YOmXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bc00c7e-2c1f-4aa8-d5a9-e871e8aa29b9"
      },
      "cell_type": "code",
      "source": [
        "output_data[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[17]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "iQmBjqr0OpWe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reshape and Normalize the input"
      ]
    },
    {
      "metadata": {
        "id": "JZ7glQoQOnsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48d21384-7b4c-4e6e-cbba-686ca0c5916b"
      },
      "cell_type": "code",
      "source": [
        "#Input Reshape is required to convert data into 3-dimensional comprising of batch_size, number of characters in one sequence and \n",
        "#how many numbers should represent each character\n",
        "input_data = np.reshape(input_data, (len(input_data),sequence_length,1))\n",
        "input_data.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(704090, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "7iOUa6CFO6Fg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have 704090 sequences each with 100 chars and each represented by 1 number."
      ]
    },
    {
      "metadata": {
        "id": "rkGSRSNtO6xx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data = input_data / vocab_size #Dividing input_data by vocab_size 86 to normalize the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RY59hYTLPBoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One hot encode the output"
      ]
    },
    {
      "metadata": {
        "id": "PESl5td-O_87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7c46247d-d90d-4e11-953f-dcfb99005673"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.utils import to_categorical\n",
        "output_data = to_categorical(output_data,num_classes=vocab_size+1)\n",
        "output_data[0:1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Qm2rhYI-PGFZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "c3XPHxUiPFbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import LSTM, Dense, Dropout\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(input_data.shape[1],input_data.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(vocab_size+1, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFr1lNPmPNWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Execute the model - Goal of the model is to minimize the loss"
      ]
    },
    {
      "metadata": {
        "id": "NLHjb-TSPO8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "eb44c16b-c57b-4100-8828-fe47986069e4"
      },
      "cell_type": "code",
      "source": [
        "model.fit(input_data, output_data, batch_size=1000, epochs=10, verbose=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 187s - loss: 3.1469\n",
            "Epoch 2/10\n",
            " - 183s - loss: 3.0603\n",
            "Epoch 3/10\n",
            " - 183s - loss: 2.9948\n",
            "Epoch 4/10\n",
            " - 184s - loss: 2.9513\n",
            "Epoch 5/10\n",
            " - 185s - loss: 2.9183\n",
            "Epoch 6/10\n",
            " - 185s - loss: 2.8786\n",
            "Epoch 7/10\n",
            " - 184s - loss: 2.8516\n",
            "Epoch 8/10\n",
            " - 185s - loss: 2.8274\n",
            "Epoch 9/10\n",
            " - 184s - loss: 2.8054\n",
            "Epoch 10/10\n",
            " - 185s - loss: 2.7841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fec8789fb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "jyDFCh5SPv-_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build random Starting point for predicting"
      ]
    },
    {
      "metadata": {
        "id": "lRY7zCA9PzIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4fac4c2-7db7-4355-a883-a8f2c2ed6e49"
      },
      "cell_type": "code",
      "source": [
        "start = np.random.randint(0, input_data.shape[0]-1)\n",
        "start"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "U1UlyhRoP2Od",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = book_num[start: start+sequence_length]\n",
        "data = [item for sublist in data for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQhYPQmFP44B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build Int to Char routine"
      ]
    },
    {
      "metadata": {
        "id": "u3Jy58tjP3KY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i,c) for c, i in t.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L30XuZXOP728",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start Predicting String"
      ]
    },
    {
      "metadata": {
        "id": "NwxEHWfFP6vU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "47922ac3-47c2-4aec-a024-bcf16ae7a3f8"
      },
      "cell_type": "code",
      "source": [
        "print ('STARTING DATA: ')\n",
        "print(''.join(int_to_char[char_val] for char_val in data))\n",
        "print ('\\nPREDICTED: ')\n",
        "\n",
        "for i in range(100):\n",
        "    #Predict for initial data\n",
        "    prediction = model.predict(np.reshape(data,(1, len(data), 1))/vocab_size)\n",
        "    \n",
        "    #Get char with max probability\n",
        "    char_index_predicted = np.argmax(prediction)\n",
        "    \n",
        "    #convert index to char\n",
        "    char_predicted = int_to_char[char_index_predicted]\n",
        "    \n",
        "    print (char_predicted, end='')\n",
        "    \n",
        "    #Change data - append new char index and remove the first index\n",
        "    data.append(char_index_predicted)\n",
        "    data = data[1:len(data)]   "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING DATA: \n",
            "all them.\n",
            "\n",
            "But the attention of every lady was soon caught by a young man, whom\n",
            "they had never seen \n",
            "\n",
            "PREDICTED: \n",
            " he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he  he "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}